{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investments Case study - EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supress Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input files for analysis of all the sections\n",
    "\n",
    "Files provided with the case study: \n",
    "\n",
    "   `companies.txt`  (file ingested in Section 1.1)<br>\n",
    "   `rounds2.csv`    (file ingested in Section 1.1)<br> \n",
    "   `mapping.csv`    (file ingested in Section 5.1) <br>\n",
    "\n",
    "#### Code Developed on 24-October-2018\n",
    "`def get_encoding(file):` <br>\n",
    ">   `file = open(file, 'rb')` <br>\n",
    ">  `tmp_file = file.read()` <br>\n",
    ">   `file.close()` <br>\n",
    ">   `detectedValue = detector.detect(tmp_file)` <br>\n",
    ">    `encoding = detectedValue['encoding']` <br>\n",
    ">    `return encoding` <br>\n",
    "\n",
    "#### Code Optimized on 01-November-2018 ; entire code executes in  0:00:33.246118 seconds\n",
    "\n",
    "##### https://pypi.org/project/python-magic/ <br>\n",
    "##### conda install -c conda-forge python-magic   <br>\n",
    "##### import magic <br>\n",
    "\n",
    "print(magic.from_file(\"companies.txt\")) <br>\n",
    "`UTF-8 Unicode text, with very long lines` <br>\n",
    "#### Windows and Linux had errors when UTF-8 was typed; this worked when we changed everything to ISO 8859-1\n",
    "print(magic.from_file(\"rounds2.csv\")) <br>\n",
    "`Non-ISO extended-ASCII text, with CRLF line terminators`\n",
    "print(magic.from_file(\"mapping.csv\")) <br>\n",
    "`ASCII text, with CRLF line terminators` <br>\n",
    "\n",
    "##### extended-ASCII is usually foreign language ; ISO 8859-1, Latin-1, mac_roman works; we have used age-old IBM way of reading encoding <br>\n",
    "###### https://en.wikipedia.org/wiki/Extended_ASCII <br>\n",
    "companies = pd.read_csv(\"companies.txt\", encoding= 'UTF-8',sep='\\t',header=0)  <br>\n",
    "rounds2 = pd.read_csv(\"rounds2.csv\" , encoding = 'ISO 8859-1') <br>\n",
    "mapping = pd.read_csv(\"mapping.csv\", encoding ='ISO 8859-1') <br>\n",
    "\n",
    "\n",
    "\n",
    "#### Special instructions for Mac OSX users to install iso3166\n",
    "##### I had this issue on Mac OSX High Sierra 10.13.6 with installation of iso3166 on conda. Just fire up terminal and `run pip install iso3166` instead of `conda install -c mcrot iso3166=0.7`:\n",
    "1. Run `conda install -c conda-forge pypdf2`<br>\n",
    "2. Run `pip install iso3166` on command line <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UTF-8 Unicode text, with very long lines\n",
      "Non-ISO extended-ASCII text, with CRLF line terminators\n",
      "ASCII text, with CRLF line terminators\n"
     ]
    }
   ],
   "source": [
    "# Import the numpy and pandas packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import chardet as detector # to detect the encoding of file\n",
    "# Use  [ conda install -c conda-forge pypdf2]  on MAC OSX 10.13.6 (17G65) to install this package\n",
    "import PyPDF2 #read pdf\n",
    "import re #Find and replace\n",
    "from iso3166 import countries #Country names for code\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# https://pypi.org/project/python-magic/\n",
    "#  conda install -c conda-forge python-magic  \n",
    "import magic\n",
    "\n",
    "# Mark the start timestamp of code execution\n",
    "startTime = datetime.now()\n",
    "\n",
    "\n",
    "\n",
    "print(magic.from_file(\"companies.txt\"))\n",
    "#UTF-8 Unicode text, with very long lines\n",
    "print(magic.from_file(\"rounds2.csv\"))\n",
    "print(magic.from_file(\"mapping.csv\"))\n",
    "#Non-ISO extended-ASCII text, with CRLF line terminators\n",
    "# extended-ASCII is usually foreign language ; ISO 8859-1, Latin-1, mac_roman works; we have used age-old IBM way of reading encoding\n",
    "# https://en.wikipedia.org/wiki/Extended_ASCII\n",
    "#Please change encoding='ISO 8859-1' ; Windows10/Mac/Linux would show UTF-8 , \n",
    "# however, code does not compile using UTF-8; changing it to 'ISO 8859-1' worked across Windows 10, Mac and Linux\n",
    "#one of our developer running Windows had issues when 'UTF-8' was used\n",
    "companies = pd.read_csv(\"companies.txt\", encoding= 'ISO 8859-1',sep='\\t',header=0) \n",
    "rounds2 = pd.read_csv(\"rounds2.csv\" , encoding = 'ISO 8859-1') # Write your code for importing the csv file here\n",
    "#mapping = pd.read_csv(\"mapping.csv\", encoding ='ISO 8859-1')\n",
    "\n",
    "#Safety first - Ensure to get correct encoding value\n",
    "#def get_encoding(file):\n",
    "#    file = open(file, 'rb')\n",
    "#    tmp_file = file.read()\n",
    "#    file.close()\n",
    "#    detectedValue = detector.detect(tmp_file)\n",
    "#    encoding = detectedValue['encoding']\n",
    "#    return encoding\n",
    "#Ensure output of 2 decimals\n",
    "#pd.options.display.float_format = \"{:.2f}\".format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unicode/non-ascii special character clean-up\n",
    "\n",
    "> We went through all the codecs (and also checked auto-detection of encoding which gave `{'encoding': 'Windows-1254', 'confidence': 0.4186155476629225, 'language': 'Turkish'}` and tried to evaluate the charset which did not miss data and skipped the error;  <br>\n",
    "\n",
    "The most suited encoding for the data set provided is `ISO 8859-1`<br> \n",
    "> https://docs.python.org/2/library/codecs.html#standard-encodings <br>\n",
    "\n",
    "#### Loading TSV\n",
    "\n",
    "> https://stackoverflow.com/questions/9652832/how-to-load-a-tsv-file-into-a-pandas-dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load TSV. SOURCE: https://stackoverflow.com/questions/9652832/how-to-load-a-tsv-file-into-a-pandas-dataframe\n",
    "#companies = pd.read_csv(\"companies.txt\", encoding = get_encoding(\"companies.txt\"),sep='\\t',header=0) \n",
    "#Load rounds CSV\n",
    "#Auto detection of encoding gave {'encoding': 'Windows-1254', 'confidence': 0.4186155476629225, 'language': 'Turkish'}\n",
    "#This resulted in error. Manual check revealed latin-1 did not miss data and skipped error.\n",
    "#rounds2 = pd.read_csv(\"rounds2.csv\", encoding = 'latin-1') # Write your code for importing the csv file here\n",
    "#Following code was used to understand the columns and encoding issues\n",
    "#print(companies.columns) #get columns\n",
    "#companies\n",
    "# Only permalink, city and name seem to have encoding issues based on output. Fixing the same\n",
    "# Converting all to uppercase and filtering any non al\n",
    "companies[['permalink', 'name','city']]=companies[['permalink', 'name','city']].astype(str).applymap(lambda x: ''.join(filter(str.isalnum, x.encode('utf-8').decode('ascii', 'ignore'))).upper())\n",
    "#Following code was used to understand the columns and encoding issues\n",
    "#print(rounds2.columns) #get columns\n",
    "#rounds2                             \n",
    "#Only company_permalink needs to be decoded from utf-8 and encoded in ascii\n",
    "#Cleanse rounds data frame. The singleton list for key avoids 'Series' object has no attribute 'applymap' exception\n",
    "rounds2[['company_permalink']]=rounds2[['company_permalink']].astype(str).applymap(lambda x: ''.join(filter(str.isalnum, x.encode('utf-8').decode('ascii', 'ignore'))).upper())\n",
    "#Initial unique rows count in companies by permalink using describe()\n",
    "# companies.permalink.describe() #select unique\n",
    "original_rows_companies= 66290\n",
    "#rounds2.company_permalink.describe() #select unique\n",
    "original_rows_rounds = 114949"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Understand the Data Set\n",
    "\n",
    "Here are our assumptions while trying to ingest, slice, dice and merge the data <br>\n",
    "\n",
    "#### Identify null percentages / drop the ones causing distortion if the percentage of drops is reasonable\n",
    "\n",
    " permalink         0.00<br>\n",
    " name              0.00<br>\n",
    " status            0.00<br>\n",
    " homepage_url      7.62 -Ignore these<br>\n",
    " `category_list     4.74 -Drop these as these cannot be analysed`<br>\n",
    " `country_code     10.48 -- attempt filling in values based on other fields?`<br>\n",
    " `state_code       12.88 -- attempt filling in the values based on other fields ; Countries without state like singapore exist.`<br>\n",
    " `region           12.10 -Drop these as these cannot be analysed`<br>\n",
    " `city             12.10 -Drop these as these cannot be analysed`<br>\n",
    " `founded_at       22.93 This is a big number - Do not touch!`<br>\n",
    "\n",
    "\n",
    "\n",
    "    1. Some companies that don't have home-page but still contain investment, we cannot ignore them \n",
    "    2. 6,238 companies are closed, we don't want to include closed companies in our analysis as it is a background noise that can be eliminated\n",
    "    3. 6,958 companies are not incorporated in any country, it is risky to consider them in our analysis. Moreover the URL is not sufficient to determine the country. For example, http://www.ardana.co.uk belongs to UK ; however majority of these contain commercial incorporated url's such as \"http://beansaround.com\" and information is not sufficient to evaluate the country of incorporation other than someone manually logging in to the url and then determining the country\n",
    "\n",
    "`companies.groupby(['status']).permalink.describe()` <br>\n",
    "\n",
    "\n",
    ">status |  count |\tunique|\ttop|\tfreq  <br>\n",
    "> acquired|\t5549|\t5549\t|/Organization/Enigma-Digital|\t1 <br>\n",
    "> `closed|\t6238|\t6238`\t|/Organization/Couchone\t|1 <br>\n",
    "> ipo|\t1547\t|1547|\t/Organization/Nitromed|\t1 <br>\n",
    "> operating\t|53034\t|53034|\t/Organization/Statace\t| <br>\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    " `companies.isnull().sum()` <br> \n",
    "\n",
    ">permalink            0 <br>\n",
    ">name                 0 <br>\n",
    ">homepage_url      5058 <br>\n",
    ">category_list     3148 <br>\n",
    ">status               0 <br>\n",
    ">`country_code      6958`  <br>\n",
    ">state_code        8547<br>\n",
    ">region            8030<br>\n",
    ">city              8028 <br>\n",
    ">founded_at       15221 <br>\n",
    "> dtype: int64<br>\n",
    "\n",
    "\n",
    "\n",
    "#### There are 156 duplicate entries with Same name and different locations\n",
    "398  ***   ORGANIZATION5MINUTES     ***    5MINUTES     ...    ***        Shanghai  ***       NaN<br> \n",
    "451  ***      ORGANIZATION5MINUTES  ***       5MINUTES     ...  ***            London *** 19-03-2011<br>\n",
    "#### Duplicate entries with and without nulls:\n",
    " 5875  ***        ORGANIZATIONBARKCO   ***        BARKCO     ...  ***          New York***  01-01-2011<br>\n",
    " 5876 ***         ORGANIZATIONBARKCO  ***         BARKCO     ...  ***          New York  ***       NaN<br>\n",
    " 59911 ***     ORGANIZATIONTVCOMPASS  ***      TVCOMPASS     ...   ***          Chicago***  01-01-2003<br>\n",
    " 59922 ***     ORGANIZATIONTVCOMPASS  ***      TVCOMPASS     ...   ***          Chicago *** 01-01-2003<br>\n",
    "#### Different permalink and name but same company due to homepage_url\n",
    " 66028    ***               ORGANIZATIONZINGBOX   ***                ZINGBOX     ...  ***    Mountain View    ***     NaN<br>\n",
    " 66030    ***            ORGANIZATIONZINGBOXLTD   ***             ZINGBOXLTD     ...  ***              NaN *** 11-11-2014<br>\n",
    " 65927    ***               ORGANIZATIONZHAOPIN    ***               ZHAOPIN     ...  ***          Beijing *** 01-01-1997<br>\n",
    " 65943    ***        ORGANIZATIONZHILIANZHAOPIN    ***        ZHILIANZHAOPIN     ...   ***         Beijing   ***      NaN<br>\n",
    "\n",
    "\n",
    "#### Null RAISED_AMOUNT_USD\n",
    "\n",
    "round(100*(rounds2.isnull().sum()/len(rounds2.index)), 2) <br>\n",
    "company_permalink           0.00 <br>\n",
    "funding_round_permalink     0.00 <br>\n",
    "funding_round_type          0.00 <br>\n",
    "funding_round_code         72.91 <br>\n",
    "funded_at                   0.00 <br>\n",
    "`raised_amount_usd          17.39` - NOT INTERESTED IN THESE <br>\n",
    "##### Companies with null homepage_url and founded_at are ok to be present in the dataframe, but, not the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows retained in companies =  49259 and Percentage of rows retained =  74.31\n",
      "Rows retained in rounds2 =  94959 and Percentage of rows retained =  82.61\n"
     ]
    }
   ],
   "source": [
    "#Clean-up\n",
    "# First find null percentages... Uncomment to see result!\n",
    "#round(100*(companies.isnull().sum()/len(companies.index)), 2)\n",
    "# permalink         0.00\n",
    "# name              0.00\n",
    "# status            0.00\n",
    "# homepage_url      7.62 -Ignore these\n",
    "# category_list     4.74 -Drop these as nothing can be done in anlysis\n",
    "# country_code     10.48 -- Fill in values based on other fields?\n",
    "# state_code       12.88 -- Fill in values based on other fields? Countries without state like singapore exist.\n",
    "# region           12.10 -Drop these as nothing can be done in anlysis\n",
    "# city             12.10 -Drop these as nothing can be done in anlysis\n",
    "# founded_at       22.93 This is a big number - Do not touch!\n",
    "# Finding duplicates : Uncomment below code if you wish to see results\n",
    "# pd.concat(c for _, c in companies.groupby(\"permalink\") if len(c) > 1)\n",
    "# reference: https://stackoverflow.com/questions/14657241/how-do-i-get-a-list-of-all-the-duplicate-items-using-pandas-in-python\n",
    "# There are 156 duplicate entries.\n",
    "# SAME NAME DIFFERENT LOCATIONS\n",
    "#398         ORGANIZATION5MINUTES         5MINUTES     ...            Shanghai         NaN\n",
    "#451         ORGANIZATION5MINUTES         5MINUTES     ...              London  19-03-2011\n",
    "# Duplicate entries with and without nulls:\n",
    "# 5875          ORGANIZATIONBARKCO           BARKCO     ...            New York  01-01-2011\n",
    "# 5876          ORGANIZATIONBARKCO           BARKCO     ...            New York         NaN\n",
    "# 59911      ORGANIZATIONTVCOMPASS        TVCOMPASS     ...             Chicago  01-01-2003\n",
    "# 59922      ORGANIZATIONTVCOMPASS        TVCOMPASS     ...             Chicago  01-01-2003\n",
    "# Different permalink and name but same company due to homepage_url\n",
    "# 66028                   ORGANIZATIONZINGBOX                   ZINGBOX     ...      Mountain View         NaN\n",
    "# 66030                ORGANIZATIONZINGBOXLTD                ZINGBOXLTD     ...                NaN  11-11-2014\n",
    "# 65927                   ORGANIZATIONZHAOPIN                   ZHAOPIN     ...            Beijing  01-01-1997\n",
    "# 65943            ORGANIZATIONZHILIANZHAOPIN            ZHILIANZHAOPIN     ...            Beijing         NaN\n",
    "\n",
    "# Any null values here?\n",
    "#round(100*(rounds2.isnull().sum()/len(rounds2.index)), 2)\n",
    "#company_permalink           0.00\n",
    "#funding_round_permalink     0.00\n",
    "#funding_round_type          0.00\n",
    "#funding_round_code         72.91\n",
    "#funded_at                   0.00\n",
    "#raised_amount_usd          17.39 - NOT INTERESTED IN THESE\n",
    "# We can have companies with null homepage_url and founded_at, but, not the rest.\n",
    "companies.dropna(subset=['category_list','region','city'],inplace=True)\n",
    "#We need to remove entries where permalink or homepage is same!\n",
    "companies.drop_duplicates(subset=['permalink'], keep=False, inplace=True)\n",
    "companies.drop_duplicates(subset=['homepage_url'], keep=False, inplace=True)\n",
    "#Status is closed... What to do? Drop them... Not needed...\n",
    "companies = companies[companies.status != 'closed']\n",
    "#Drop data on companies which have not generated funds...\n",
    "rounds2.dropna(subset=['raised_amount_usd'],inplace=True)\n",
    "rows_retained_companies = len(companies.isnull().sum(axis=1).index)\n",
    "rows_retained_rounds = len(rounds2.isnull().sum(axis=1).index)\n",
    "rows_retained_companies_percentage = round((rows_retained_companies)/original_rows_companies*100,2)\n",
    "rows_retained_rounds_percentage =round((rows_retained_rounds)/original_rows_rounds*100,2)\n",
    "print (\"Rows retained in companies = \",rows_retained_companies,\"and Percentage of rows retained = \",rows_retained_companies_percentage)\n",
    "print (\"Rows retained in rounds2 = \",rows_retained_rounds,\"and Percentage of rows retained = \",rows_retained_rounds_percentage)\n",
    "#Still having 74.31 % of rows in companies and 82.61 % of rows in rounds. Good to go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint 1\n",
    "#### Code and answer for Section 1.1\n",
    "\n",
    "`Note:` <br>\n",
    "\n",
    "`1.The Coding cell is immedeately followed by Markdown table, team has updated results in the markdown table as per requirements in addition to updating results in the spreadsheet` <br>\n",
    "`2.Code is very clearly commented and print statements put up in the same manner for avoiding any confusion`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53861 unique rows in rounds2.\n",
      "49259 unique rows in companies.\n",
      "Difference of rounds2 and companies tables (after cleaning): 16560 Companies\n",
      "Total number of observations in master_frame is 78399\n"
     ]
    }
   ],
   "source": [
    "# NOTE: We have already filtered the data for most possible anamolies. Hence the numbers in answers are for the subset we consider analysable.\n",
    "# Code for Section 1.1 goes here. The next cell has Markdown table, please update results in the markdown table as well\n",
    "# ****************************************************************************\n",
    "# Understand the Data Set\n",
    "#****************************************************************************\n",
    "#How many unique companies are present in rounds2?\n",
    "print(len(rounds2.company_permalink.unique()),\"unique rows in rounds2.\")\n",
    "#unique                     53861\n",
    "#-------------------------------------------------------------------------------\n",
    "# How many unique companies are present in companies?   \n",
    "# One possible way to ask is companies.describe\n",
    "# Take care to check how many companies are repeating. Same home page - 119 Companies, Same name - 265 Companies\n",
    "# Otherwise, it is 66368 based on just permalink\n",
    "print(len(companies.permalink.unique()),\"unique rows in companies.\")\n",
    "# unique                    49259\n",
    "#-------------------------------------------------------------------------------\n",
    "#In the companies data frame, which column can be used as the unique key for each company? Write the name of the column.\n",
    "# companies.describe()\n",
    "#premalink is uinque and not null. Hence it should be used as unique key. URL is repeated for some.\n",
    "companies.set_index(\"permalink\", inplace = True)\n",
    "#-------------------------------------------------------------------------------\n",
    "# Are there any companies in the rounds2 file which are not present in companies? Answer yes or no: Y/N\t \n",
    "# Answer : Yes\n",
    "print(\"Difference of rounds2 and companies tables (after cleaning):\", len([x for x in rounds2.company_permalink if x not in companies.index]), \"Companies\")\n",
    "# Write your code here...\n",
    "#-------------------------------------------------------------------------------\n",
    "# Merge the two data frames so that all variables (columns) in the companies frame are added to the rounds2 data frame. Name the merged frame master_frame. How many observations are present in master_frame?\n",
    "master_frame = rounds2.merge(companies,how='inner',left_on = 'company_permalink',right_on = 'permalink')\n",
    "#Convert amount to billions of usd - do not round as it counts small amounts\n",
    "master_frame['raised_amount_usd'] = master_frame.raised_amount_usd/1000000\n",
    "master_frame.rename( columns= {\"raised_amount_usd\":\"raised_amount_million_usd\"}, inplace=True)\n",
    "print(\"Total number of observations in master_frame is\",len(master_frame))\n",
    "#-------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Answer for Section 1.1\n",
    "#### Table 1.1: Understand the Data Set \n",
    "\n",
    "\n",
    "<table border =\"1\" width=700>\n",
    "    <tr>\n",
    "        <td>How many unique companies are present in rounds2?</td> \n",
    "        <td> 53861 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>How many unique companies are present in companies?\t</td> \n",
    "        <td> 49259 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>In the companies data frame, which column can be used as the unique key for each company? Write the name of the column.</td> \n",
    "        <td>  permalink </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Are there any companies in the rounds2 file which are not present in companies? Answer yes or no: Y/N</td> \n",
    "        <td> Y </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Merge the two data frames so that all variables (columns) in the companies frame are added to the rounds2 data frame. Name the merged frame master_frame. How many observations are present in master_frame?</td> \n",
    "        <td> 78399 </td>\n",
    "    </tr>\n",
    "    \n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint 2\n",
    "\n",
    "#### Code and answer for Section 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raised_amount_million_usd    11.879979\n",
      "Name: venture, dtype: float64\n",
      "raised_amount_million_usd    0.994762\n",
      "Name: angel, dtype: float64\n",
      "raised_amount_million_usd    0.762296\n",
      "Name: seed, dtype: float64\n",
      "raised_amount_million_usd    73.331531\n",
      "Name: private_equity, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Code for Section 2.1 goes here. The next cell has Markdown table, please update results in the markdown table as well\n",
    "# ****************************************************************************\n",
    "#Table 2.1: Average Values of Investments for Each of these Funding Types \n",
    "# ****************************************************************************\n",
    "\n",
    "#Average funding amount of venture type\t\n",
    "print (master_frame.groupby('funding_round_type').mean().loc['venture'])\n",
    "#raised_amount_usd    11.88\n",
    "#-------------------------------------------------------------------------------\n",
    "# Average funding amount of angel type\t \n",
    "print (master_frame.groupby('funding_round_type').mean().loc['angel'])\n",
    "#raised_amount_usd    0.99\n",
    "#-------------------------------------------------------------------------------\n",
    "# Average funding amount of seed type\t \n",
    "print (master_frame.groupby('funding_round_type').mean().loc['seed'])\n",
    "#raised_amount_usd    0.76\n",
    "#-------------------------------------------------------------------------------\n",
    "# Average funding amount of private equity type\t \n",
    "print (master_frame.groupby('funding_round_type').mean().loc['private_equity'])\n",
    "#raised_amount_usd    73.33\n",
    "#-------------------------------------------------------------------------------\n",
    "# Considering that Spark Funds wants to invest between 5 to 15 million USD per investment round, which investment type is the most suitable for it?\n",
    "# Venture...\n",
    "                                                                                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Answer for Section 2.1\n",
    "#### Table 2.1: Average Values of Investments for Each of these Funding Types \n",
    "\n",
    "\n",
    "<table border =\"1\" width=700>\n",
    "    <tr>\n",
    "        <td>Average funding amount of venture type</td> \n",
    "         <td> \n",
    "        | Type of Investment    | Million USD | <br>\n",
    "        |-----------------------|:-----------:|  <br>\n",
    "        | venture               | 11.88       |  <br>\n",
    "       </td>\n",
    "    </tr>\n",
    "     <tr>\n",
    "        <td>Average funding amount of angel type</td> \n",
    "        <td> \n",
    "        | Type of Investment    | Million USD | <br>\n",
    "        |-----------------------|:-----------:|  <br>\n",
    "        | angel               | 0.99       |  <br>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "    <tr>\n",
    "        <td>Average funding amount of seed type</td> \n",
    "        <td> \n",
    "        | Type of Investment    | Million USD | <br>\n",
    "        |-----------------------|:-----------:|  <br>\n",
    "        | seed               | 0.76      |  <br>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Average funding amount of private equity type\t </td> \n",
    "        <td> \n",
    "        | Type of Investment    | Million USD | <br>\n",
    "        |-----------------------|:-----------:|  <br>\n",
    "        | private_equity               | 73.33       |  <br>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Considering that Spark Funds wants to invest between 5 to 15 million USD per investment round, which investment type is the most suitable for it?</td> \n",
    "        <td> Venture, 11.88M US$ </td>\n",
    "    </tr>\n",
    "    \n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint 3\n",
    "#### Code and answer for Section 3.1\n",
    "\n",
    "Use `PyPDF2` to read `Countries_where_English_is_an_official_language.pdf` and print top 9 countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              raised_amount_million_usd\n",
      "country_code                           \n",
      "USA                       375805.380141\n",
      "CHN                        34432.116713\n",
      "GBR                        16762.922982\n",
      "IND                        13456.066718\n",
      "CAN                         8244.403575\n",
      "FRA                         6169.320568\n",
      "ISR                         6011.867458\n",
      "DEU                         5833.951235\n",
      "SWE                         2842.573022\n",
      "Top English speaking country: United States\n",
      "Second English speaking country: United Kingdom\n",
      "Third English speaking country: India\n"
     ]
    }
   ],
   "source": [
    "# Code for Section 3.1 goes here. The next cell has Markdown table, please update results in the markdown table as well\n",
    "#Spark Funds wants to see the top nine countries which have received the highest total funding (across ALL sectors for the chosen investment type - venture)\n",
    "#For the chosen investment type, make a data frame named top9 with the top nine countries (based on the total investment amount each country has received)\n",
    "top9= master_frame[master_frame['funding_round_type'] == 'venture'].groupby('country_code').sum().sort_values(by = 'raised_amount_million_usd', ascending = False)[:9]\n",
    "#index is ['USA', 'CHN', 'GBR', 'IND', 'CAN', 'FRA', 'ISR', 'DEU', 'SWE']\n",
    "#Make a pretty display\n",
    "print(top9)\n",
    "#Load list of english speaking countries\n",
    "pdfFileObj = open('Countries_where_English_is_an_official_language.pdf', 'rb')\n",
    "pdfReader = PyPDF2.PdfFileReader(pdfFileObj) \n",
    "pageObj = pdfReader.getPage(0)\n",
    "englist_continents_countries= ' '.join(re.sub(r\"(\\w)([A-Z])\", r\"\\1 \\2\",pageObj.extractText()).splitlines()[1:])\n",
    "pdfFileObj.close()\n",
    "top9_country_names={' '.join( countries.get(country).apolitical_name.split()[:2]):country for country in top9.index}\n",
    "top3_english_country_names=[name for name in list(top9_country_names.keys()) if name in  englist_continents_countries][:3]\n",
    "# ****************************************************************************\n",
    "# Table 3.1: Analysing the Top 3 English-Speaking Countries\n",
    "# ****************************************************************************\n",
    "#-------------------------------------------------------------------------------\n",
    "#Top English-speaking country\t              \n",
    "print(\"Top English speaking country:\",top3_english_country_names[0])\n",
    "#-------------------------------------------------------------------------------\n",
    "#Second English-speaking country\t \n",
    "print(\"Second English speaking country:\",top3_english_country_names[1])\n",
    "#------------------------------------------------------------------------------    \n",
    "#Third English-speaking country\t \n",
    "print(\"Third English speaking country:\",top3_english_country_names[2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer for section 3.1\n",
    "#### Table 3.1: Analysing the Top 3 English-Speaking Countries\n",
    "\n",
    "\n",
    "<table border =\"1\" width=700>\n",
    "    <tr>\n",
    "        <td>Top English speaking country</td> \n",
    "         <td> \n",
    "UNITED STATES OF AMERICA [375,805.38 Mil USD]\n",
    "       </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Second English speaking country</td> \n",
    "        <td> UNITED KINGDOM\t[16,762.92 Mil USD] </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Third English speaking country\t </td> \n",
    "        <td>  INDIA [\t13,456.07  Mil USD]   </td>\n",
    "    </tr>\n",
    "\n",
    "</table>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint 5\n",
    "#### Code for Section 5.1 - Dataframe preparation for analysis in section 5.2\n",
    "\n",
    "This section leverages on data preparation done in all the cells above. In addition `Mapping.csv` is ingested to merge with the earlier dataframe; Also note that `32` categories were missing and we had to fix them\n",
    "\n",
    "`These missing categories could not be ignored as they had quite a number of rounds of investments associated with them. Including them gives us more leverage on the data and hence the fortified analysis`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixing 0 in category_list...\n",
      "Fixing case in category_list...\n",
      "Created primary_sector in master_frame\n",
      "Missing number of categories: 32 found\n",
      "Fixing missing categories...\n",
      "mapped primary_sector to main_sector in master_frame\n",
      "Dropping blanks in master frame...\n"
     ]
    }
   ],
   "source": [
    "#Data Prep Sector Analysis 1 (5.1)\n",
    "#Read Mapping file into a data frame\n",
    "mapping = pd.read_csv(\"mapping.csv\", encoding ='ISO 8859-1')\n",
    "# mapping = pd.read_csv(\"mapping.csv\", encoding = get_encoding(\"mapping.csv\"))\n",
    "mapping.dropna(subset=['category_list'],inplace=True)\n",
    "#Someone did a find and replace of na with 0... Also words are not in proper case...\n",
    "#Replace na\n",
    "print (\"Fixing 0 in category_list...\")\n",
    "mapping['category_list'] = list(map( lambda x: re.sub(r\"0\", r\"na\", x), mapping.category_list))\n",
    "#Bruteforce to upper\n",
    "print (\"Fixing case in category_list...\")\n",
    "mapping['category_list'] = mapping['category_list'].str.upper()\n",
    "\n",
    "#extract first column from master_Frame ; numerous columns are present separated by a '|'\n",
    "master_frame['primary_sector'] = master_frame['category_list'].str.split('|',1,expand=True)[0]\n",
    "print ('Created primary_sector in master_frame')\n",
    "\n",
    "#Some categories are missing...\n",
    "print(\"Missing number of categories:\",len({x for x in master_frame['primary_sector'].str.upper() if x not in list(mapping.category_list)}), \"found\")\n",
    "print (\"Fixing missing categories...\")\n",
    "\n",
    "#Fixing them\n",
    "labels =['category_list','Automotive & Sports', 'Blanks', 'Cleantech / Semiconductors', 'Entertainment', 'Health', 'Manufacturing', 'News, Search and Messaging', 'Others','Social, Finance, Analytics, Advertising']\n",
    "\n",
    "extras = [('GROUP EMAIL',0,0,0,0,0,0,1,0,0), \n",
    " ('KINECT',0,0,0,1,0,0,0,0,0), \n",
    " ('ENTERPRISE 2.0',0,0,0,0,0,1,0,0,0), \n",
    " ('REGISTRARS',0,0,0,0,0,0,0,1,0), \n",
    " ('VACATION RENTALS',0,0,0,0,0,0,0,0,1), \n",
    " ('SPECIALTY RETAIL',0,0,0,0,0,0,0,0,1), \n",
    " ('INTERNET TECHNOLOGY',0,0,0,0,0,0,1,0,0), \n",
    " ('RAPIDLY EXPANDING',0,0,0,0,0,0,0,1,0), \n",
    " ('NATURAL GAS USES',0,0,0,0,0,0,0,1,0), \n",
    " ('ENTERPRISE HARDWARE',0,0,0,0,0,1,0,0,0), \n",
    " ('LINGERIE',0,0,0,0,0,0,0,1,0), \n",
    " ('GREENTECH',0,0,1,0,0,0,0,0,0), \n",
    " ('CAUSE MARKETING',0,0,0,0,0,0,0,0,1), \n",
    " ('SPAS',0,0,0,0,1,0,0,0,0), \n",
    " ('PSYCHOLOGY',0,0,0,0,1,0,0,0,0), \n",
    " ('INTERNET TV',0,0,0,1,0,0,0,0,0), \n",
    " ('GOOGLE GLASS',0,0,0,1,0,0,0,0,0), \n",
    " ('DEEP INFORMATION TECHNOLOGY',0,0,0,0,0,0,1,0,0), \n",
    " ('SOCIAL MEDIA ADVERTISING',0,0,0,0,0,0,0,0,1), \n",
    " ('REAL ESTATE INVESTORS',0,0,0,0,0,0,0,0,1), \n",
    " ('BIOTECHNOLOGY AND SEMICONDUCTOR',0,0,1,0,0,0,0,0,0), \n",
    " ('SKILL GAMING',1,0,0,0,0,0,0,0,0), \n",
    " ('SWIMMING',1,0,0,0,0,0,0,0,0), \n",
    " ('ADAPTIVE EQUIPMENT',1,0,0,0,0,0,0,0,0), \n",
    " ('GOLF EQUIPMENT',1,0,0,0,0,0,0,0,0), \n",
    " ('GENERATION Y-Z',0,0,0,0,0,0,0,0,1), \n",
    " ('TOYS',0,0,0,0,0,0,0,1,0), \n",
    " ('MOBILE EMERGENCY&HEALTH',0,0,0,0,1,0,0,0,0),\n",
    " ('ENGLISH-SPEAKING',0,0,0,0,0,0,0,0,1),\n",
    " ('NIGHTLIFE',0,0,0,1,0,0,0,0,0),\n",
    " ('SEX INDUSTRY',0,0,0,1,0,0,0,0,0),\n",
    " ('SPONSORSHIP',0,0,0,0,0,0,0,1,0)\n",
    "]\n",
    "mapping_extras = pd.DataFrame.from_records(extras,columns=labels)\n",
    "mapping = pd.concat([mapping,mapping_extras])\n",
    "mapping.set_index('category_list',inplace=True)\n",
    "\n",
    "#map sector\n",
    "master_frame['main_sector'] = list(map(lambda x : list(mapping.columns[mapping.loc[x.upper()] == 1])[0], master_frame['primary_sector']))\n",
    "print ('mapped primary_sector to main_sector in master_frame')\n",
    "#drop Blanks\n",
    "print ('Dropping blanks in master frame...')\n",
    "master_frame = master_frame[master_frame['main_sector'] != 'Blanks']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 5.2  - Sector analysis\n",
    "\n",
    "##### 1. Please note that  favourite `venture` investment ( best investment between `5 Million-15 Million USD`) is chosen within each round of investment markup planning\n",
    "##### 2. `English as official language` countries are chosen to facilitate the ease of business/investment\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Value \t\t\t\t\t\t\tUnited States \tUnited Kingdom \tIndia\n",
      "Total number of investments\t\t\t\t 10698 \t\t 528 \t\t 307\n",
      "Total amount(Million USD) of investments\t\t 95678.87 \t 4604.06 \t 2739.67\n",
      "Top sector (based on investments count)\t\t\t Others \n",
      "\t\t\t\t\t\t\t\t\t Others \n",
      "\t\t\t\t\t\t\t\t\t\t\t Others\n",
      "Second-best sector (based on investments count)\t\t Social, Finance, Analytics, Advertising \n",
      "\t\t\t\t\t\t\t\t\t Social, Finance, Analytics, Advertising \n",
      "\t\t\t\t\t\t\t\t\t\t\t Social, Finance, Analytics, Advertising\n",
      "Third-best sector (based on investments count)\t\t Cleantech / Semiconductors \n",
      "\t\t\t\t\t\t\t\t\t Cleantech / Semiconductors \n",
      "\t\t\t\t\t\t\t\t\t\t\t News, Search and Messaging\n",
      "Total number of investments in the top sector\t\t 2563 \t\t 125 \t\t 102\n",
      "Total number of investments in the second-best sector\t 2504 \t\t 123 \t\t 57\n",
      "Total number of investmentsin the third-best sector\t 2064 \t\t 103 \t\t 20\n",
      "company with highest investment in top sector\t\t VIRTUSTREAM \t ELECTRICCLOUD \t FIRSTCRYCOM\n",
      "company with highest investment in second-best sector\t SSTINCFORMERLYSHOTSPOTTER \t CELLTICKTECHNOLOGIES \t MANTHANSYSTEMS\n"
     ]
    }
   ],
   "source": [
    "#Sector analysis -2 code goes here\n",
    "#Conditions as per problem statement\n",
    "country_1 = top9_country_names['United States']\n",
    "country_2 = top9_country_names['United Kingdom']\n",
    "country_3 = top9_country_names['India']\n",
    "ft='venture'\n",
    "\n",
    "#Creating filters. Reusable this way...\n",
    "filter1 = (master_frame['country_code'] == country_1) &  (master_frame['funding_round_type']==ft) & (master_frame['raised_amount_million_usd'] >= 5.0) & (master_frame['raised_amount_million_usd'] <= 15.0)\n",
    "filter2 = (master_frame['country_code'] == country_2) &  (master_frame['funding_round_type']==ft) & (master_frame['raised_amount_million_usd'] >= 5.0) & (master_frame['raised_amount_million_usd'] <= 15.0)\n",
    "filter3 = (master_frame['country_code'] == country_3) &  (master_frame['funding_round_type']==ft) & (master_frame['raised_amount_million_usd'] >= 5.0) & (master_frame['raised_amount_million_usd'] <= 15.0)\n",
    "\n",
    "#Total investment by main sector...\n",
    "total_investment1=master_frame[['main_sector','raised_amount_million_usd']][filter1].groupby('main_sector').sum().sort_values(by='raised_amount_million_usd',ascending=False)\n",
    "total_investment2=master_frame[['main_sector','raised_amount_million_usd']][filter2].groupby('main_sector').sum().sort_values(by='raised_amount_million_usd',ascending=False)\n",
    "total_investment3=master_frame[['main_sector','raised_amount_million_usd']][filter3].groupby('main_sector').sum().sort_values(by='raised_amount_million_usd',ascending=False)\n",
    "number_investment1=master_frame[['main_sector','funded_at']][filter1].groupby('main_sector').count().sort_values(by='funded_at',ascending=False)\n",
    "number_investment2=master_frame[['main_sector','funded_at']][filter2].groupby('main_sector').count().sort_values(by='funded_at',ascending=False)\n",
    "number_investment3=master_frame[['main_sector','funded_at']][filter3].groupby('main_sector').count().sort_values(by='funded_at',ascending=False)\n",
    "\n",
    "# Create D1, D2 and D3\n",
    "D1 = master_frame [filter1]\n",
    "D2 = master_frame [filter2]\n",
    "D3 = master_frame [filter3]\n",
    "\n",
    "d1_meta = pd.merge(total_investment1,number_investment1,on='main_sector')\n",
    "d1_meta.rename(index=str, columns={'raised_amount_million_usd':'total_invested',  'funded_at':'number_investments'},inplace=True)\n",
    "d2_meta = pd.merge(total_investment2,number_investment2,on='main_sector')\n",
    "d2_meta.rename(index=str, columns={'raised_amount_million_usd':'total_invested',  'funded_at':'number_investments'},inplace=True)\n",
    "d3_meta = pd.merge(total_investment3,number_investment3,on='main_sector')\n",
    "d3_meta.rename(index=str, columns={'raised_amount_million_usd':'total_invested',  'funded_at':'number_investments'},inplace=True)\n",
    "print ('\\nValue','\\t\\t\\t\\t\\t\\t\\tUnited States','\\tUnited Kingdom','\\tIndia')\n",
    "# 1. Total number of investments (count)\n",
    "print('Total number of investments\\t\\t\\t\\t', d1_meta.number_investments.sum(),'\\t\\t',d2_meta.number_investments.sum(),'\\t\\t',d3_meta.number_investments.sum())\n",
    "# 2. Total amount of investment (USD)\n",
    "print('Total amount(Million USD) of investments\\t\\t', round(d1_meta.total_invested.sum(),2),'\\t',round(d2_meta.total_invested.sum(),2),'\\t',round(d3_meta.total_invested.sum(),2))\n",
    "# 3. Top sector (based on count of investments)\n",
    "#(note that ‘Other’ is one of the eight main sectors)\n",
    "print('Top sector (based on investments count)\\t\\t\\t', d1_meta.number_investments.index[0],'\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t',d2_meta.number_investments.index[0],'\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t',d3_meta.number_investments.index[0])\n",
    "# 4. Second-best sector (based on count of investments)\n",
    "print('Second-best sector (based on investments count)\\t\\t', d1_meta.number_investments.index[1],'\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t',d2_meta.number_investments.index[1],'\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t',d3_meta.number_investments.index[1])\n",
    "# 5. Third-best sector (based on count of investments)\n",
    "print('Third-best sector (based on investments count)\\t\\t', d1_meta.number_investments.index[2],'\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t',d2_meta.number_investments.index[2],'\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t',d3_meta.number_investments.index[2])\n",
    "# 6. Number of investments in the top sector (refer to point 3)\n",
    "print('Total number of investments in the top sector\\t\\t', d1_meta.number_investments.loc[d1_meta.number_investments.index[0]],'\\t\\t',d2_meta.number_investments.loc[d1_meta.number_investments.index[0]],'\\t\\t',d3_meta.number_investments.loc[d1_meta.number_investments.index[0]])\n",
    "# 7. Number of investments in the second-best sector (refer to point 4)\n",
    "print('Total number of investments in the second-best sector\\t', d1_meta.number_investments.loc[d1_meta.number_investments.index[1]],'\\t\\t',d2_meta.number_investments.loc[d1_meta.number_investments.index[1]],'\\t\\t',d3_meta.number_investments.loc[d1_meta.number_investments.index[1]])\n",
    "# 8. Number of investments in the third-best sector (refer to point 5)\n",
    "print('Total number of investmentsin the third-best sector\\t', d1_meta.number_investments.loc[d1_meta.number_investments.index[2]],'\\t\\t',d2_meta.number_investments.loc[d1_meta.number_investments.index[2]],'\\t\\t',d3_meta.number_investments.loc[d1_meta.number_investments.index[2]])\n",
    "top_d1_companies = D1[['company_permalink','name','raised_amount_million_usd']][D1['main_sector']==d1_meta.number_investments.index[0]].groupby(['name','company_permalink']).sum().sort_values('raised_amount_million_usd',ascending=False)\n",
    "top_d2_companies = D2[['company_permalink','name','raised_amount_million_usd']][D2['main_sector']==d2_meta.number_investments.index[0]].groupby(['name','company_permalink']).sum().sort_values('raised_amount_million_usd',ascending=False)\n",
    "top_d3_companies = D3[['company_permalink','name','raised_amount_million_usd']][D3['main_sector']==d3_meta.number_investments.index[0]].groupby(['name','company_permalink']).sum().sort_values('raised_amount_million_usd',ascending=False)\n",
    "second_d1_companies = D1[['company_permalink','name','raised_amount_million_usd']][D1['main_sector']==d1_meta.number_investments.index[1]].groupby(['name','company_permalink']).sum().sort_values('raised_amount_million_usd',ascending=False)\n",
    "second_d2_companies = D2[['company_permalink','name','raised_amount_million_usd']][D2['main_sector']==d2_meta.number_investments.index[1]].groupby(['name','company_permalink']).sum().sort_values('raised_amount_million_usd',ascending=False)\n",
    "second_d3_companies = D3[['company_permalink','name','raised_amount_million_usd']][D3['main_sector']==d3_meta.number_investments.index[1]].groupby(['name','company_permalink']).sum().sort_values('raised_amount_million_usd',ascending=False)\n",
    "\n",
    "# 9. For the top sector count-wise (point 3), which company received the highest investment?\n",
    "print('company with highest investment in top sector\\t\\t',top_d1_companies.index[0][0],'\\t',top_d2_companies.index[0][0],'\\t',top_d3_companies.index[0][0])\n",
    "\n",
    "#10. For the second-best sector count-wise (point 4), which company received the highest investment?\n",
    "print('company with highest investment in second-best sector\\t',second_d1_companies.index[0][0],'\\t',second_d2_companies.index[0][0],'\\t',second_d3_companies.index[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table 5.1 : Sector-wise Investment Analysis\n",
    "<table border =\"1\" width=700>\n",
    "    <th>\n",
    "        <td>United States</td>\n",
    "        <td>United Kingdom</td>\n",
    "        <td>India</td>\n",
    "    </th>\n",
    "    <tr>\n",
    "        <td>1. Total number of investments</td>\n",
    "        <td>10698</td>\n",
    "        <td>528</td>\n",
    "        <td>307</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>2. Total amount(Million USD) of investments</td>\n",
    "        <td>95678.87</td>\n",
    "        <td>4604.06</td>\n",
    "        <td>2739.67</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>3. Top sector (based on investments count)</td>\n",
    "        <td>Others</td>\n",
    "        <td>Others</td>\n",
    "        <td>Others</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>4. Second-best sector (based on investments count)</td>\n",
    "        <td>Social, Finance, Analytics, Advertising</td>\n",
    "        <td>Social, Finance, Analytics, Advertising</td>\n",
    "        <td>Social, Finance, Analytics, Advertising</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>5. Third-best sector (based on investments count)</td>\n",
    "        <td>Cleantech \\ Semiconductors</td>\n",
    "        <td>Cleantech \\ Semiconductors</td>\n",
    "        <td>News, Search and Messaging</td>\n",
    "    </tr>\n",
    "    <tr><td>6. Total number of investments in the top sector</td>\n",
    "        <td>2563</td>\n",
    "        <td>125</td>\n",
    "        <td>102</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>7. Total number of investments in the second-best sector</td>\n",
    "        <td>2504</td>\n",
    "        <td>123</td>\n",
    "        <td>57</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>8. Total number of investmentsin the third-best sector</td>\n",
    "        <td>2064</td>\n",
    "        <td>103</td>\n",
    "        <td>20</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>9. Company with highest investment in top sector</td>\n",
    "        <td>Virtustream</td>\n",
    "        <td>Electric Cloud</td>\n",
    "        <td>First Cry</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>10. Company with highest investment in second-best sector</td>\n",
    "        <td>SST Inc. Formerly Shot Spotter</td>\n",
    "        <td>Cell Tick Technologies</td>\n",
    "        <td>Manthan Systems</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Presentation -  Output files for Tableau plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output three dataframes to three csv files that will be imported in Tableau for further analysis\n",
    "#\n",
    "top9['Country Name']=[name.upper() for name in list(top9_country_names.keys())]\n",
    "top3 = (pd.concat([D1, D2, D3 ], axis = 0))\n",
    "top3_country_names={' '.join( countries.get(country).apolitical_name.split()[:2]):country for country in top3.country_code}\n",
    "#print(top3_country_names)\n",
    "#{'United States': 'USA', 'United Kingdom': 'GBR', 'India': 'IND'}\n",
    "D1['Country Name'] = 'UNITED STATES OF AMERICA'\n",
    "D2['Country Name'] = 'UNITED KINGDOM'\n",
    "D3['Country Name'] = 'INDIA'\n",
    "top3 = (pd.concat([D1, D2, D3 ], axis = 0))\n",
    "#\n",
    "# Output master frame from section 2.1\n",
    "master_frame.to_csv(\"total_investments.csv\", sep=',')\n",
    "# Output top 9 countries from section 3.1 \n",
    "top9.to_csv(\"top9_analysis.csv\", sep=',')\n",
    "# Output top 3 country data frames that has additional data from sections 5.1 and 5.2\n",
    "top3.to_csv(\"top3_analysis.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time elasped:  0:00:35.007022\n"
     ]
    }
   ],
   "source": [
    "print('\\nTime elasped: ', datetime.now() - startTime)\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assess the time taken for code execution\n",
    "##### For larger data frames this would be very good checkmark to optimize code execution; for dataset of this size, we believe that the performance for the analysis questions in this workbook is optimum\n",
    "\n",
    "`Time elasped:  0:00:30.659647`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
