{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Case Study\n",
    "Citizens of New York City, a thriving metropolis face many challenges, one of the biggest being parking. They are frequently served parking tickets due to high number of cars and limited parking spaces in the city.\n",
    "\n",
    "#### Purpose of the Case study:\n",
    "\n",
    "The NYPD (NYC Police Department) has collected data for parking tickets to enable them to serve citizens better. Of these, the data files for multiple years are publicly available on Kaggle. This case study attempts to perform some exploratory analysis on a part of this data over the year **2017**. We will use Spark, a Big Data tool, to analyse the full files provided instead of taking a series of random samples that will approximate the population. We will answer questions as asked in the problem statement. <br>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Assumptions and Directions in Assignment\n",
    "\n",
    "##### Please ensure Kernel is `PySpark`\n",
    "\n",
    "1. The data for this case study is present in HDFS at the following path: `/common_folder/nyc_parking/Parking_Violations_Issued_-_Fiscal_Year_2017.csv` \n",
    "2. The exploratory data analysis is specifically for year 2017 and hence any other years will be ignored\n",
    "3. We need to clean data as we progress through the questions due to nature of the questions asked\n",
    "4. We are free to use `Spark SQL` Queries and PySpark DataFrame Methods as required.\n",
    "5. To enable us to answer the questions posed in a more efficient way, we can use other `Python libraries` such as `pandas`, `numpy` and `matplotlib`\n",
    "6. Data will be cleaned in a particular column if no directions/hint is provided for any particular question\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, year, countDistinct, when, isnan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a spark session. We prfer use of session\n",
    "# instead of context as it is more efficient\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName('Spark Case Study') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the file from specified location\n",
    "# Ensure to filter header and infer schema\n",
    "# along with specifying date format\n",
    "nyc_df = spark.read \\\n",
    "           .format(\"csv\") \\\n",
    "           .options(header='true', inferSchema='true', dateFormat='yyyy-MM-dd')\\\n",
    "           .load(\"/common_folder/nyc_parking/Parking_Violations_Issued_-_Fiscal_Year_2017.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace white spaces with _ charecter for easier access\n",
    "alias_list = [col(column).alias(column.replace(' ', '_')) for column in nyc_df.columns]\n",
    "nyc_df = nyc_df.select(*alias_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0---------------------------------\n",
      " Summons_Number     | 5092469481          \n",
      " Plate_ID           | GZH7067             \n",
      " Registration_State | NY                  \n",
      " Issue_Date         | 2016-07-10 00:00:00 \n",
      " Violation_Code     | 7                   \n",
      " Vehicle_Body_Type  | SUBN                \n",
      " Vehicle_Make       | TOYOT               \n",
      " Violation_Precinct | 0                   \n",
      " Issuer_Precinct    | 0                   \n",
      " Violation_Time     | 0143A               \n",
      "-RECORD 1---------------------------------\n",
      " Summons_Number     | 5092451658          \n",
      " Plate_ID           | GZH7067             \n",
      " Registration_State | NY                  \n",
      " Issue_Date         | 2016-07-08 00:00:00 \n",
      " Violation_Code     | 7                   \n",
      " Vehicle_Body_Type  | SUBN                \n",
      " Vehicle_Make       | TOYOT               \n",
      " Violation_Precinct | 0                   \n",
      " Issuer_Precinct    | 0                   \n",
      " Violation_Time     | 0400P               \n",
      "-RECORD 2---------------------------------\n",
      " Summons_Number     | 4006265037          \n",
      " Plate_ID           | FZX9232             \n",
      " Registration_State | NY                  \n",
      " Issue_Date         | 2016-08-23 00:00:00 \n",
      " Violation_Code     | 5                   \n",
      " Vehicle_Body_Type  | SUBN                \n",
      " Vehicle_Make       | FORD                \n",
      " Violation_Precinct | 0                   \n",
      " Issuer_Precinct    | 0                   \n",
      " Violation_Time     | 0233P               \n",
      "-RECORD 3---------------------------------\n",
      " Summons_Number     | 8478629828          \n",
      " Plate_ID           | 66623ME             \n",
      " Registration_State | NY                  \n",
      " Issue_Date         | 2017-06-14 00:00:00 \n",
      " Violation_Code     | 47                  \n",
      " Vehicle_Body_Type  | REFG                \n",
      " Vehicle_Make       | MITSU               \n",
      " Violation_Precinct | 14                  \n",
      " Issuer_Precinct    | 14                  \n",
      " Violation_Time     | 1120A               \n",
      "-RECORD 4---------------------------------\n",
      " Summons_Number     | 7868300310          \n",
      " Plate_ID           | 37033JV             \n",
      " Registration_State | NY                  \n",
      " Issue_Date         | 2016-11-21 00:00:00 \n",
      " Violation_Code     | 69                  \n",
      " Vehicle_Body_Type  | DELV                \n",
      " Vehicle_Make       | INTER               \n",
      " Violation_Precinct | 13                  \n",
      " Issuer_Precinct    | 13                  \n",
      " Violation_Time     | 0555P               \n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display a sample of 5 records in a pretty format\n",
    "nyc_df.show(5,vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------------\n",
      " Summons_Number     | 5092469481 \n",
      " Plate_ID           | GZH7067    \n",
      " Registration_State | NY         \n",
      " Issue_Date         | 2016-07-10 \n",
      " Violation_Code     | 7          \n",
      " Vehicle_Body_Type  | SUBN       \n",
      " Vehicle_Make       | TOYOT      \n",
      " Violation_Precinct | 0          \n",
      " Issuer_Precinct    | 0          \n",
      " Violation_Time     | 0143A      \n",
      "-RECORD 1------------------------\n",
      " Summons_Number     | 5092451658 \n",
      " Plate_ID           | GZH7067    \n",
      " Registration_State | NY         \n",
      " Issue_Date         | 2016-07-08 \n",
      " Violation_Code     | 7          \n",
      " Vehicle_Body_Type  | SUBN       \n",
      " Vehicle_Make       | TOYOT      \n",
      " Violation_Precinct | 0          \n",
      " Issuer_Precinct    | 0          \n",
      " Violation_Time     | 0400P      \n",
      "-RECORD 2------------------------\n",
      " Summons_Number     | 4006265037 \n",
      " Plate_ID           | FZX9232    \n",
      " Registration_State | NY         \n",
      " Issue_Date         | 2016-08-23 \n",
      " Violation_Code     | 5          \n",
      " Vehicle_Body_Type  | SUBN       \n",
      " Vehicle_Make       | FORD       \n",
      " Violation_Precinct | 0          \n",
      " Issuer_Precinct    | 0          \n",
      " Violation_Time     | 0233P      \n",
      "-RECORD 3------------------------\n",
      " Summons_Number     | 8478629828 \n",
      " Plate_ID           | 66623ME    \n",
      " Registration_State | NY         \n",
      " Issue_Date         | 2017-06-14 \n",
      " Violation_Code     | 47         \n",
      " Vehicle_Body_Type  | REFG       \n",
      " Vehicle_Make       | MITSU      \n",
      " Violation_Precinct | 14         \n",
      " Issuer_Precinct    | 14         \n",
      " Violation_Time     | 1120A      \n",
      "-RECORD 4------------------------\n",
      " Summons_Number     | 7868300310 \n",
      " Plate_ID           | 37033JV    \n",
      " Registration_State | NY         \n",
      " Issue_Date         | 2016-11-21 \n",
      " Violation_Code     | 69         \n",
      " Vehicle_Body_Type  | DELV       \n",
      " Vehicle_Make       | INTER      \n",
      " Violation_Precinct | 13         \n",
      " Issuer_Precinct    | 13         \n",
      " Violation_Time     | 0555P      \n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Force DateTime record of Issue_Date to be a Date only Record\n",
    "# There is a difference between Issue and Violation time stamps\n",
    "# As per the kaggle dictionary. We will retain this.\n",
    "# Reason: A ticket can be issued post violation by mail.\n",
    "nyc_df = nyc_df.withColumn('Issue_Date',col('Issue_Date').cast(\"Date\"))\n",
    "nyc_df.show(5,vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Summons_Number: long (nullable = true)\n",
      " |-- Plate_ID: string (nullable = true)\n",
      " |-- Registration_State: string (nullable = true)\n",
      " |-- Issue_Date: date (nullable = true)\n",
      " |-- Violation_Code: integer (nullable = true)\n",
      " |-- Vehicle_Body_Type: string (nullable = true)\n",
      " |-- Vehicle_Make: string (nullable = true)\n",
      " |-- Violation_Precinct: integer (nullable = true)\n",
      " |-- Issuer_Precinct: integer (nullable = true)\n",
      " |-- Violation_Time: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Display the Schema\n",
    "nyc_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the data\n",
    "For the scope of this analysis, we will analyse the parking tickets over the year 2017.\n",
    "\n",
    "**Question 1:**`Find the total number of tickets for the year`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "|Year|Tickets|\n",
      "+----+-------+\n",
      "|1990|      2|\n",
      "|2025|      6|\n",
      "|1977|      1|\n",
      "|2027|     50|\n",
      "|2003|      1|\n",
      "|2007|     18|\n",
      "|2018|   1057|\n",
      "|1974|      1|\n",
      "|2015|    419|\n",
      "|2023|      5|\n",
      "|2047|      2|\n",
      "|2069|      4|\n",
      "|2062|      2|\n",
      "|2006|      8|\n",
      "|2022|      4|\n",
      "|2031|      5|\n",
      "|2013|     70|\n",
      "|1997|      1|\n",
      "|2026|     24|\n",
      "|1994|      1|\n",
      "|2014|    120|\n",
      "|1973|      2|\n",
      "|2041|      1|\n",
      "|2019|    472|\n",
      "|2036|      1|\n",
      "|2060|      2|\n",
      "|2004|      2|\n",
      "|1991|      3|\n",
      "|2029|      2|\n",
      "|2030|     12|\n",
      "|1996|      1|\n",
      "|2053|      1|\n",
      "|2068|      1|\n",
      "|2020|     22|\n",
      "|1985|      1|\n",
      "|2012|     87|\n",
      "|2033|      2|\n",
      "|2009|      3|\n",
      "|2016|5368391|\n",
      "|2061|      1|\n",
      "|2001|      2|\n",
      "|2028|      8|\n",
      "|2024|      3|\n",
      "|1972|      2|\n",
      "|2005|      1|\n",
      "|1984|      1|\n",
      "|2000|    185|\n",
      "|2010|     48|\n",
      "|2011|     22|\n",
      "|1976|      1|\n",
      "|2008|      4|\n",
      "|2017|5431918|\n",
      "|2063|      2|\n",
      "|2002|      1|\n",
      "|2021|     22|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# register temp view\n",
    "#nyc_df.createOrReplaceTempView(\"nyc_dfTable\")\n",
    "# Find Ticket grouped by Years to get correct count\n",
    "\n",
    "# Uncomment if you want a SQL way of getting the answer\n",
    "# Both solutions are equivalent\n",
    "\n",
    "# spark.sql(\"\"\"\n",
    "#                 SELECT Year(issue_date)                   AS Year,\n",
    "#                        Count(DISTINCT ( summons_number )) AS Tickets\n",
    "#                 FROM   nyc_dftable\n",
    "#                 GROUP  BY year\n",
    "#                 ORDER  BY year  \n",
    "#            \"\"\").show(55)\n",
    "\n",
    "#Using pyspark dataframe functions to achieve one of the assignment goals\n",
    "nyc_df.select(year(col('Issue_Date')).alias('Year'),'Summons_Number')\\\n",
    "              .groupBy('Year').agg(countDistinct('Summons_Number').alias('Tickets'))\\\n",
    "              .show(55)#.count() yields 55. So, show all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just to demonstrate  SQL returns same answer , uncomment SQL and comment Python code:  \n",
    "#nyc_df = spark.sql(\"\"\" \n",
    "#                        SELECT *\n",
    "#                        FROM   nyc_dftable\n",
    "#                        WHERE  Year(issue_date) = 2017 \n",
    "#                    \"\"\") \n",
    "nyc_df = nyc_df.filter(year(col('Issue_Date')) == 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "|Year|Tickets|\n",
      "+----+-------+\n",
      "|2017|5431918|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nyc_df.select(year(col('Issue_Date')).alias('Year'),'Summons_Number')\\\n",
    "              .groupBy('Year').agg(countDistinct('Summons_Number').alias('Tickets'))\\\n",
    "              .show()#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics of violations:\n",
      "+-------+------------------+--------------------+\n",
      "|summary|    Violation_Code|      Summons_Number|\n",
      "+-------+------------------+--------------------+\n",
      "|  count|           5431918|             5431918|\n",
      "|   mean| 35.05772196855696| 7.116377503346856E9|\n",
      "| stddev|19.332822159461614|2.2941358232098784E9|\n",
      "|    min|                 0|          1002884949|\n",
      "|    max|                99|          8585600044|\n",
      "+-------+------------------+--------------------+\n",
      "\n",
      "Statistics of violations:\n",
      "+-------+------------------+--------------------+\n",
      "|summary|    Violation_Code|      Summons_Number|\n",
      "+-------+------------------+--------------------+\n",
      "|  count|           5431691|             5431691|\n",
      "|   mean| 35.05918709293294|7.1163223769480095E9|\n",
      "| stddev|19.331897645688496| 2.294161894739209E9|\n",
      "|    min|                 1|          1002884949|\n",
      "|    max|                99|          8585600044|\n",
      "+-------+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Statistics of violations:')\n",
    "nyc_df.describe(['Violation_Code','Summons_Number']).show()\n",
    "# There is no violation code 0. Only 1-99\n",
    "# as per https://www1.nyc.gov/site/finance/vehicles/services-violation-codes.page\n",
    "# We need to discard this set as it is erroneous set of values\n",
    "nyc_df = nyc_df.filter(col('Violation_Code') > 0)\n",
    "print('Statistics of violations:')\n",
    "nyc_df.describe(['Violation_Code','Summons_Number']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  SQL style - preferred as its easy\n",
    "nyc_df.createOrReplaceTempView(\"nyc_dfTable\")\n",
    "#Query yielded a length of 65 rows in count. So, showing 65 rows\n",
    "spark.sql(\"\"\"\n",
    "                SELECT *\n",
    "                FROM   nyc_dftable\n",
    "                WHERE  summons_number IS NULL  \n",
    "            \"\"\").count()\n",
    "# THERE ARE NO NULL SUMMONS NUMBERS\n",
    "# We can count and even replace easily if we use PySpark DataFrame functions\n",
    "# nyc_df.select('Summons_Number').na.fill(0).where(nyc_df.Summons_Number == 0).count()\n",
    "# THERE ARE NO NULL SUMMONS NUMBERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "|Year|Tickets|\n",
      "+----+-------+\n",
      "|2017|5431691|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PySpark Data Frame methods\n",
    "nyc_df.select(year(col('Issue_Date')).alias('Year'),'Summons_Number')\\\n",
    "              .groupBy('Year').agg(countDistinct('Summons_Number').alias('Tickets'))\\\n",
    "              .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. There were no NULL values in Tickets\n",
    "2. Erroneous violaion codes were removed\n",
    "3. We only counted distinct summons number to avoid duplicates.\n",
    "4. `Violation Precinct` is not treated as a later question expects errors.\n",
    "\n",
    "The actual number of tickets in 2017 with valid information is **5431691**.\n",
    "\n",
    "**Question 2.** `Find out the number of unique states from where the cars that got parking tickets came.`\n",
    "\n",
    "(Hint: Use the column 'Registration State'.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of records:  65\n",
      "+------------+-------+\n",
      "|Origin_State|Tickets|\n",
      "+------------+-------+\n",
      "|          NY|4273870|\n",
      "|          NJ| 475813|\n",
      "|          PA| 140286|\n",
      "|          CT|  70401|\n",
      "|          FL|  69468|\n",
      "|          IN|  45525|\n",
      "|          MA|  38940|\n",
      "|          VA|  34366|\n",
      "|          MD|  30212|\n",
      "|          NC|  27152|\n",
      "|          TX|  18827|\n",
      "|          IL|  18665|\n",
      "|          GA|  17537|\n",
      "|          99|  15930|\n",
      "|          AZ|  12378|\n",
      "|          OH|  12281|\n",
      "|          CA|  12153|\n",
      "|          ME|  10806|\n",
      "|          SC|  10395|\n",
      "|          MN|  10083|\n",
      "|          OK|   9088|\n",
      "|          TN|   8514|\n",
      "|          DE|   7905|\n",
      "|          MI|   7231|\n",
      "|          RI|   5813|\n",
      "|          NH|   4119|\n",
      "|          VT|   3683|\n",
      "|          AL|   3178|\n",
      "|          WA|   3052|\n",
      "|          OR|   2622|\n",
      "|          MO|   2483|\n",
      "|          ON|   2460|\n",
      "|          WI|   2127|\n",
      "|          QB|   1998|\n",
      "|          IA|   1938|\n",
      "|          DC|   1929|\n",
      "|          CO|   1841|\n",
      "|          KY|   1795|\n",
      "|          DP|   1794|\n",
      "|          LA|   1689|\n",
      "|          MS|   1582|\n",
      "|          WV|   1265|\n",
      "|          AR|    994|\n",
      "|          SD|    859|\n",
      "|          NM|    792|\n",
      "|          ID|    763|\n",
      "|          NV|    725|\n",
      "|          KS|    706|\n",
      "|          NE|    703|\n",
      "|          UT|    561|\n",
      "|          MT|    505|\n",
      "|          GV|    348|\n",
      "|          NS|    322|\n",
      "|          AK|    298|\n",
      "|          ND|    254|\n",
      "|          WY|    188|\n",
      "|          HI|    156|\n",
      "|          AB|     79|\n",
      "|          PE|     61|\n",
      "|          NB|     57|\n",
      "|          BC|     54|\n",
      "|          PR|     38|\n",
      "|          MB|     17|\n",
      "|          SK|      9|\n",
      "|          FO|      8|\n",
      "+------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SQL style\n",
    "nyc_df.createOrReplaceTempView(\"nyc_dfTable\")\n",
    "#Query yielded a length of 65 rows in count. this count is automatically pulled into count variable before printing\n",
    "count = spark.sql(\"\"\"\n",
    "                SELECT registration_state                 AS Origin_State,\n",
    "                       Count(DISTINCT ( summons_number )) AS Tickets\n",
    "                FROM   nyc_dftable\n",
    "                GROUP  BY origin_state\n",
    "                ORDER  BY tickets DESC \n",
    "           \"\"\").count()\n",
    "print(\"total number of records: \", count)\n",
    "spark.sql(\"\"\"\n",
    "                SELECT registration_state                 AS Origin_State,\n",
    "                       Count(DISTINCT ( summons_number )) AS Tickets\n",
    "                FROM   nyc_dftable\n",
    "                GROUP  BY origin_state\n",
    "                ORDER  BY tickets DESC \n",
    "           \"\"\").show(count)\n",
    "#PySpark DataFrame Methonds\n",
    "#Query yielded a length of 65 rows in count. So, showing 65 rows\n",
    "#nyc_df.select(col('Registration_State').alias('Origin_State'),'Summons_Number')\\\n",
    "#              .groupBy('Origin_State').agg(countDistinct('Summons_Number').alias('Tickets'))\\\n",
    "#              .orderBy('Tickets',ascending=False)\\\n",
    "#              .show(65)#.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Direction in Question 2:**\n",
    "\n",
    "There is a numeric entry '99' in the column, which should be corrected. Replace it with the state having the maximum entries. Provide the number of unique states again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#99 has 16055 Tickets. NY has most tickets - 4273951.\n",
    "# Replace 99 by NY. It is simple to do in PySpark\n",
    "nyc_df = nyc_df.withColumn(\"Registration_State\", \\\n",
    "              when(nyc_df[\"Registration_State\"] == '99', 'NY')\\\n",
    "                           .otherwise(nyc_df[\"Registration_State\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  64  unique jurisdictions of origin for offeneders who were issued tickets.\n",
      "The Top 5 states in order of tickets issued are:\n",
      "+------------+-------+\n",
      "|Origin_State|Tickets|\n",
      "+------------+-------+\n",
      "|          NY|4289800|\n",
      "|          NJ| 475813|\n",
      "|          PA| 140286|\n",
      "|          CT|  70401|\n",
      "|          FL|  69468|\n",
      "+------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#nyc_df.printSchema()\n",
    "# refresh temp view\n",
    "nyc_df.createOrReplaceTempView(\"nyc_dfTable\")\n",
    "\n",
    "states = spark.sql(\"\"\"\n",
    "                        SELECT registration_state                 AS Origin_State,\n",
    "                               Count(DISTINCT ( summons_number )) AS Tickets\n",
    "                        FROM   nyc_dftable\n",
    "                        GROUP  BY origin_state\n",
    "                        ORDER  BY tickets DESC \n",
    "                    \"\"\")\n",
    "\n",
    "#Get states and print pretty!\n",
    "#states = nyc_df.select(col('Registration_State').alias('Origin_State'),'Summons_Number')\\\n",
    "#              .groupBy('Origin_State').agg(countDistinct('Summons_Number').alias('Tickets'))\\\n",
    "#              .orderBy('Tickets',ascending=False)\n",
    "print('There are ',states.count(),' unique jurisdictions of origin for offeneders who were issued tickets.')\n",
    "print ('The Top 5 states in order of tickets issued are:')\n",
    "states.show(5)#use 64 to list all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answers and Observations:**\n",
    "1. The total number of tickets issued in 2017 was 5431691.\n",
    " \n",
    "2. There are ony 50 states in the USA. AS a result, there are a total of 64 jurisdictions of origin for vehicles with parking tickets. New York has most tickets (4290006), followed by New Jersey,Pennsylvania, Connecticut and Florida. \n",
    "\n",
    "Most of the tickets are issued to Newyorkers. The data shows that the city has many vehicles coming in from other states, especially those that are very near by. This traffic forces Nywyorkers to violate parking regulations and get Tickets issued. If these visitors can be made to use taxis and public transport, the challenges due to high traffic can be reduced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation Queries\n",
    "**Question 1:**\n",
    "\n",
    "`How often does each violation code occur? Display the frequency of the top five violation codes.`\n",
    "(Hint: Find the top 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics of violations:\n",
      "+-------+------------------+--------------------+\n",
      "|summary|    Violation_Code|      Summons_Number|\n",
      "+-------+------------------+--------------------+\n",
      "|  count|           5431691|             5431691|\n",
      "|   mean| 35.05918709293294|7.1163223769480095E9|\n",
      "| stddev|19.331897645688496|2.2941618947392097E9|\n",
      "|    min|                 1|          1002884949|\n",
      "|    max|                99|          8585600044|\n",
      "+-------+------------------+--------------------+\n",
      "\n",
      "Listing frequency of top 5 violation codes in the year 2017\n",
      "+--------------+-------+\n",
      "|Violation_Code|Tickets|\n",
      "+--------------+-------+\n",
      "|            21| 768087|\n",
      "|            36| 662765|\n",
      "|            38| 542079|\n",
      "|            14| 476664|\n",
      "|            20| 319646|\n",
      "+--------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# refresh temp view\n",
    "print('Statistics of violations:')\n",
    "nyc_df.describe(['Violation_Code','Summons_Number']).show()\n",
    "\n",
    "#Display Frequency of tickets per code.\n",
    "print('Listing frequency of top 5 violation codes in the year 2017')\n",
    "nyc_df.select(col('Violation_Code'),'Summons_Number')\\\n",
    "              .groupBy('Violation_Code').agg(countDistinct('Summons_Number').alias('Tickets'))\\\n",
    "              .orderBy('Tickets',ascending=False)\\\n",
    "              .show(5) #Replace with 99 for all as count() yielded 99 records\n",
    "#SQL style...\n",
    "# refresh temp view\n",
    "#nyc_df.createOrReplaceTempView(\"nyc_dfTable\")\n",
    "#print('Listing frequency of violations in a year')\n",
    "#Display Frequency of violations in the year.\n",
    "#spark.sql(\"\"\"\n",
    "#                SELECT violation_code,\n",
    "#                       Count(DISTINCT ( summons_number )) AS Tickets\n",
    "#                FROM   nyc_dftable\n",
    "#                GROUP  BY violation_code\n",
    "#                ORDER  BY tickets DESC \n",
    "#            \"\"\").show(5)#Replace with 99 for all as count() yielded 99 records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codes 21, 36, 38, 14 and 20 are the most frequent violations in the `year 2017`\n",
    "\n",
    "**Question 2.1 :**`How often does each 'vehicle body type' get a parking ticket?`\n",
    "(Hint: Find the top 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing top 5 vehicle body types base on ticket counts\n",
      "+-----------------+-------+\n",
      "|Vehicle_Body_Type|Tickets|\n",
      "+-----------------+-------+\n",
      "|             SUBN|1883933|\n",
      "|             4DSD|1547283|\n",
      "|              VAN| 724022|\n",
      "|             DELV| 358980|\n",
      "|              SDN| 194195|\n",
      "+-----------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Listing top 5 vehicle body types base on ticket counts')\n",
    "nyc_df.select(col('Vehicle_Body_Type'),'Summons_Number')\\\n",
    "              .groupBy('Vehicle_Body_Type').agg(countDistinct('Summons_Number').alias('Tickets'))\\\n",
    "              .orderBy('Tickets',ascending=False)\\\n",
    "              .show(5) #Replace with 1165 for all as count() yielded 1165 records\n",
    "\n",
    "#Display Top 5 in SQL style query...\n",
    "#nyc_df.createOrReplaceTempView(\"nyc_dfTable\")\n",
    "#print('Listing top 5 vehicle body types with ticket counts')\n",
    "#Display Top 5\n",
    "#spark.sql(\"\"\"\n",
    "#                SELECT vehicle_body_type,\n",
    "#                       COUNT(DISTINCT ( summons_number )) AS Tickets \n",
    "#                FROM   nyc_dftable \n",
    "#                GROUP  BY vehicle_body_type \n",
    "#                ORDER  BY tickets desc  \n",
    "#           \n",
    "#           \"\"\").show(5)#Replace with 1165 for all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing top 5 vehicle body types base on ticket counts\n",
      "+-----------------+-------+\n",
      "|Vehicle_Body_Type|Tickets|\n",
      "+-----------------+-------+\n",
      "|             SUBN|1884040|\n",
      "|             4DSD|1547292|\n",
      "|              VAN| 724128|\n",
      "|             DELV| 359041|\n",
      "|             SEDN| 197293|\n",
      "+-----------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reference: https://data.ny.gov/Transportation/Vehicle-Makes-and-Body-Types-Most-Popular-in-New-Y/3pxy-wy2i\n",
    "# On listing, we found codes that were mistyped\n",
    "# Assuming closest matches and\n",
    "# replacing them correctly to get exact counts\n",
    "# SUBU SUB SUBA are SUBN\n",
    "# FDSD is 4DSD\n",
    "# VANT, VAND, VAN. VANF, VANH are VAN\n",
    "# DELI, DELT, DEL, DELA, DELO are DELV\n",
    "# SEDA (Found boat make, but, no body type. Correcting to SEDN),SEDN,SDN to be SEDN\n",
    "nyc_df = nyc_df.withColumn(\"Vehicle_Body_Type\", \\\n",
    "              when(nyc_df[\"Vehicle_Body_Type\"].isin(['SUBU', 'SUB', 'SUBA']), 'SUBN')\\\n",
    "                           .otherwise(nyc_df[\"Vehicle_Body_Type\"]))\n",
    "nyc_df = nyc_df.withColumn(\"Vehicle_Body_Type\", \\\n",
    "              when(nyc_df[\"Vehicle_Body_Type\"] == 'FDSD', '4DSD')\\\n",
    "                           .otherwise(nyc_df[\"Vehicle_Body_Type\"]))\n",
    "nyc_df = nyc_df.withColumn(\"Vehicle_Body_Type\", \\\n",
    "              when(nyc_df[\"Vehicle_Body_Type\"].isin(['VANT', 'VAND', 'VAN.', 'VANF', 'VANH']), 'VAN')\\\n",
    "                           .otherwise(nyc_df[\"Vehicle_Body_Type\"]))\n",
    "nyc_df = nyc_df.withColumn(\"Vehicle_Body_Type\", \\\n",
    "              when(nyc_df[\"Vehicle_Body_Type\"].isin(['DELI', 'DELT', 'DEL', 'DELA', 'DELO']), 'DELV')\\\n",
    "                           .otherwise(nyc_df[\"Vehicle_Body_Type\"]))\n",
    "nyc_df = nyc_df.withColumn(\"Vehicle_Body_Type\", \\\n",
    "              when(nyc_df[\"Vehicle_Body_Type\"].isin(['SEDA','SEDN','SDN']), 'SEDN')\\\n",
    "                           .otherwise(nyc_df[\"Vehicle_Body_Type\"]))\n",
    "print('Listing top 5 vehicle body types base on ticket counts')\n",
    "nyc_df.select(col('Vehicle_Body_Type'),'Summons_Number')\\\n",
    "              .groupBy('Vehicle_Body_Type').agg(countDistinct('Summons_Number').alias('Tickets'))\\\n",
    "              .orderBy('Tickets',ascending=False)\\\n",
    "              .show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer and Observation**\n",
    "Suburban (SUBN), four-door sedan (4DSD), Van Truck (VAN),Delivery Truck (DELV) and Sedan (SEDN) are the top 5 body types in records. The highest violation frequency is of Suburban (almost 1.9 million times in a year).\n",
    "\n",
    "Most of these vehicles are used for transport and delivery. This indicates that drivers are driven by required delivery/arrival time to violate regulations. Evenly distributed special parking zones for such vehicles can ease traffic challenges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2 :**`How about the 'vehicle make'?`(Hint: Find the top 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing top 5 vehicle makes base on ticket counts\n",
      "+------------+-------+\n",
      "|Vehicle_Make|Tickets|\n",
      "+------------+-------+\n",
      "|        FORD| 636838|\n",
      "|       TOYOT| 605279|\n",
      "|       HONDA| 538875|\n",
      "|       NISSA| 462011|\n",
      "|       CHEVR| 356026|\n",
      "+------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Listing top 5 vehicle makes base on ticket counts')\n",
    "nyc_df.select(col('Vehicle_Make'),'Summons_Number')\\\n",
    "              .groupBy('Vehicle_Make').agg(countDistinct('Summons_Number').alias('Tickets'))\\\n",
    "              .orderBy('Tickets',ascending=False)\\\n",
    "              .show(5) #Replace with 3179 for all as count() yielded 3179 records\n",
    "\n",
    "#Display Top 5 in SQL style query...\n",
    "#nyc_df.createOrReplaceTempView(\"nyc_dfTable\")\n",
    "#print('Listing top 5 vehicle makes with ticket counts')\n",
    "#Display Top 5\n",
    "#spark.sql('SELECT Vehicle_Make, COUNT(DISTINCT (Summons_Number)) as Tickets \\\n",
    "#           FROM nyc_dfTable \\\n",
    "#           GROUP BY Vehicle_Make \\\n",
    "#           ORDER BY Tickets DESC').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing top 5 vehicle body types base on ticket counts\n",
      "+------------+-------+\n",
      "|Vehicle_Make|Tickets|\n",
      "+------------+-------+\n",
      "|        FORD| 636847|\n",
      "|       TOYOT| 605279|\n",
      "|       HONDA| 538878|\n",
      "|       NISSA| 462015|\n",
      "|       CHEVR| 356050|\n",
      "+------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reference: https://data.ny.gov/Transportation/Vehicle-Makes-and-Body-Types-Most-Popular-in-New-Y/3pxy-wy2i\n",
    "# On listing, we found codes that were mistyped\n",
    "# Assuming closest matches and\n",
    "# replacing them correctly to get exact counts\n",
    "# FORDB, FORDU, Ford, FORE, FOREL, FORLE,  FOREN are FORD\n",
    "# HONSA, HONRA are HONDA\n",
    "# NISN, NISSZ, NISSR are NISSA\n",
    "# Chevr,CHEVO,CHEVG,CHEVV, CHV to be CHEVR\n",
    "nyc_df = nyc_df.withColumn(\"Vehicle_Make\", \\\n",
    "              when(nyc_df[\"Vehicle_Make\"].isin(['FORDB', 'FORDU', 'Ford', 'FORE', 'FOREL', 'FORLE',  'FOREN']), 'FORD')\\\n",
    "                           .otherwise(nyc_df[\"Vehicle_Make\"]))\n",
    "nyc_df = nyc_df.withColumn(\"Vehicle_Make\", \\\n",
    "              when(nyc_df[\"Vehicle_Make\"].isin(['HONSA', 'HONRA']), 'HONDA')\\\n",
    "                           .otherwise(nyc_df[\"Vehicle_Make\"]))\n",
    "nyc_df = nyc_df.withColumn(\"Vehicle_Make\", \\\n",
    "              when(nyc_df[\"Vehicle_Make\"].isin(['NISN', 'NISSZ', 'NISSR']), 'NISSA')\\\n",
    "                           .otherwise(nyc_df[\"Vehicle_Make\"]))\n",
    "nyc_df = nyc_df.withColumn(\"Vehicle_Make\", \\\n",
    "              when(nyc_df[\"Vehicle_Make\"].isin(['Chevr','CHEVO','CHEVG','CHEVV', 'CHV']), 'CHEVR')\\\n",
    "                           .otherwise(nyc_df[\"Vehicle_Make\"]))\n",
    "\n",
    "print('Listing top 5 vehicle body types base on ticket counts')\n",
    "nyc_df.select(col('Vehicle_Make'),'Summons_Number')\\\n",
    "              .groupBy('Vehicle_Make').agg(countDistinct('Summons_Number').alias('Tickets'))\\\n",
    "              .orderBy('Tickets',ascending=False)\\\n",
    "              .show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " `FORD, TOYOTA, HONDA, NISSAN and CHEVROLET are the top 5 body types in records `\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3) `A precinct is a police station that has a certain zone of the city under its command. Find the (5 highest) frequencies of tickets for:`\n",
    "##### a. `Violation Precinct` (This is the precinct of the zone where the violation occurred).\n",
    "\n",
    "##### NOTE: Here, you would have noticed that the dataframe has the'Violating Precinct' as '0'. These are erroneous entries. Hence, you need to provide the records for five correct precincts. (Hint: Print the top six entries after sorting.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing top 5 Precinct (count includes 0 hence top 6) where violations occured with ticket counts\n",
      "+------------------+-------+\n",
      "|violation_precinct|Tickets|\n",
      "+------------------+-------+\n",
      "|                 0| 925405|\n",
      "|                19| 274443|\n",
      "|                14| 203552|\n",
      "|                 1| 174702|\n",
      "|                18| 169129|\n",
      "|               114| 147443|\n",
      "+------------------+-------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nyc_df.createOrReplaceTempView(\"nyc_dfTable\")\n",
    "print('Listing top 5 Precinct (count includes 0 hence top 6) where violations occured with ticket counts')\n",
    "#Display Top 5  \n",
    "spark.sql(\"\"\"\n",
    "                SELECT violation_precinct,\n",
    "                       COUNT(DISTINCT ( summons_number )) AS Tickets \n",
    "                FROM   nyc_dftable \n",
    "                GROUP  BY violation_precinct \n",
    "                ORDER  BY tickets desc  \n",
    "            \"\"\").show(6)#Replace with (count) for showing all records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Using this, can you draw any insights for parking violations in any specific areas of the city?`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b. `Issuer Precinct` (This is the precinct that issued the ticket.)\n",
    "\n",
    "NOTE: Here, you would have noticed that the dataframe has the'Issuer Precinct' as '0'. These are erroneous entries. Hence, you need to provide the records for five correct precincts. \n",
    "\n",
    "(Hint: Print the top six entries after sorting.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing top 5 Precinct (count includes 0 hence top 6) Precinct by tickets issued with ticket counts\n",
      "+---------------+-------+\n",
      "|issuer_precinct|Tickets|\n",
      "+---------------+-------+\n",
      "|              0|1078215|\n",
      "|             19| 266959|\n",
      "|             14| 200494|\n",
      "|              1| 168740|\n",
      "|             18| 162992|\n",
      "|            114| 144053|\n",
      "+---------------+-------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nyc_df.createOrReplaceTempView(\"nyc_dfTable\")\n",
    "print('Listing top 5 Precinct (count includes 0 hence top 6) Precinct by tickets issued with ticket counts')\n",
    "#Display Top 5  \n",
    "# \n",
    "spark.sql(\"\"\"\n",
    "             SELECT issuer_precinct,\n",
    "                   COUNT(DISTINCT ( summons_number )) AS Tickets \n",
    "            FROM   nyc_dftable \n",
    "            GROUP  BY issuer_precinct \n",
    "            ORDER  BY tickets desc \n",
    "\n",
    "            \"\"\").show(6)#Replace with (count) for showing all records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `Using this, can you draw any insights for parking violations in any specific areas of the city?`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `4) Find the violation code frequencies for three precincts that have issued the most number of tickets.` \n",
    "(Hint: In the SQL view, use the 'where' attribute to filter among three precincts.)\n",
    "`Do these precinct zones have an exceptionally high frequency of certain violation codes?` `Are these codes common across precincts?` <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing violation code frequencies per precinct with ticket counts\n",
      "+---------------+--------------+-------+\n",
      "|issuer_precinct|violation_code|Tickets|\n",
      "+---------------+--------------+-------+\n",
      "|             19|            46|  48445|\n",
      "|             19|            38|  36386|\n",
      "|             19|            37|  36056|\n",
      "|             19|            14|  29797|\n",
      "|             19|            21|  28415|\n",
      "|             14|            14|  45036|\n",
      "|             14|            69|  30464|\n",
      "|             14|            31|  22555|\n",
      "|             14|            47|  18364|\n",
      "|             14|            42|  10027|\n",
      "|              1|            14|  38354|\n",
      "|              1|            16|  19081|\n",
      "|              1|            20|  15408|\n",
      "|              1|            46|  12745|\n",
      "|              1|            38|   8535|\n",
      "+---------------+--------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import show\n",
    "\n",
    "nyc_df.createOrReplaceTempView(\"nyc_dfTable\")\n",
    "print('Listing violation code frequencies per precinct with ticket counts')\n",
    "#Displays all the violation codes for precincts 19, 14 and 1 \n",
    "# uncomment the code below if you would like to see all\n",
    "# \n",
    "#nyc_pdf = spark.sql(\"\"\"\n",
    "#                        SELECT issuer_precinct,\n",
    "#                               violation_code,\n",
    "#                               COUNT(DISTINCT ( summons_number )) AS Tickets \n",
    "#                        FROM   nyc_dftable \n",
    "#                        WHERE  issuer_precinct in ( 19  ,14 , 1  )\n",
    "#                        GROUP  BY issuer_precinct,\n",
    "#                                  violation_code \n",
    "#                        ORDER  BY issuer_precinct,\n",
    "#                                  tickets desc    \n",
    "#       \"\"\").toPandas()\n",
    "# nyc_pdf.sort_values(by='Tickets',ascending=False)\n",
    "# ax = nyc_pdf.plot.scatter(x='violation_code', y='tickets', c='issuer_precinct', colormap='viridis')\n",
    "# ax.set_xticks(np.arange(0, 100, 1))\n",
    "# show()\n",
    "\n",
    "\n",
    "# Print top 5 violation codes across three precincts \n",
    "\n",
    "nyc_pdf = spark.sql(\"\"\"\n",
    "                         SELECT *\n",
    "                        FROM   (SELECT '19' as issuer_precinct, * \n",
    "                                        FROM   (SELECT  violation_code,\n",
    "                                               Count(DISTINCT summons_number) AS Tickets\n",
    "                                        FROM   nyc_dftable\n",
    "                                        WHERE  issuer_precinct = 19\n",
    "                                        GROUP  BY violation_code\n",
    "                                        ORDER by Tickets desc\n",
    "                                        limit 5) inner_q) outer_q  -- Display top 5 violation codes \n",
    "                        union all\n",
    "                                SELECT *\n",
    "                        FROM   (SELECT '14' as issuer_precinct, * \n",
    "                                        FROM   (SELECT  violation_code,\n",
    "                                               Count(DISTINCT summons_number) AS Tickets\n",
    "                                        FROM   nyc_dftable\n",
    "                                        WHERE  issuer_precinct = 14\n",
    "                                        GROUP  BY violation_code\n",
    "                                        ORDER by Tickets desc\n",
    "                                        limit 5) inner_q) outer_q    -- Display top 5 violation codes \n",
    "                        union all\n",
    "                                SELECT *\n",
    "                        FROM   (SELECT '1' as issuer_precinct, * \n",
    "                                        FROM   (SELECT  violation_code,\n",
    "                                               Count(DISTINCT summons_number) AS Tickets\n",
    "                                        FROM   nyc_dftable\n",
    "                                        WHERE  issuer_precinct = 1\n",
    "                                        GROUP  BY violation_code\n",
    "                                        ORDER by Tickets desc\n",
    "                                        limit 5) inner_q) outer_q   -- Display top 5 violation codes \n",
    "                   \"\"\").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inference\n",
    "1) Violation codes `46` and  `14` tops the list of violations in precincts `19` and `14 & 1` respectively <br>\n",
    "2) Violation code `14` is common among all three precincts considering `Top 5 violation codes`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### 5) `Find out the properties of parking violations across different times of the day.` \n",
    "a) `Find a way to deal with missing values, if any.` <br>\n",
    "\n",
    "Hint: Check for the null values using 'isNull' under the SQL. Also, to remove the null values, check the 'dropna' command in the API documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyc_df.where(col(\"Violation_Time\").isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyc_df.where(col(\"Violation_Time\")=='nan').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropNA is not useful as it is nan string\n",
    "nyc_df = nyc_df.where(col(\"Violation_Time\")!='nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|Violation_Time|\n",
      "+--------------+\n",
      "|          0557|\n",
      "|         110+A|\n",
      "|         093+A|\n",
      "|          0855|\n",
      "|         075/P|\n",
      "|         09.5A|\n",
      "|         073/A|\n",
      "|         09+1A|\n",
      "|         10.3P|\n",
      "|          0515|\n",
      "|         06.5A|\n",
      "|         09.5A|\n",
      "|         06+0P|\n",
      "|          0316|\n",
      "|         0.47A|\n",
      "|          0651|\n",
      "|         065+A|\n",
      "|         074/A|\n",
      "|         10+1A|\n",
      "|         125+A|\n",
      "|         093+A|\n",
      "|         09+2A|\n",
      "|          1037|\n",
      "|         083.A|\n",
      "|         08+7A|\n",
      "|          0446|\n",
      "|         04080|\n",
      "|         081*A|\n",
      "|         015.A|\n",
      "|         103/P|\n",
      "|         10.0P|\n",
      "|         .933A|\n",
      "|         094/P|\n",
      "|         121/P|\n",
      "|         115+A|\n",
      "|         100.P|\n",
      "|         07.8A|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nyc_df.select('Violation_Time').where('NOT Violation_Time rlike \"^[0-9]{4}[A|P]$\"').show(37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropNA is not useful as it is nan string\n",
    "nyc_df = nyc_df.where('Violation_Time rlike \"^[0-9]{4}[A|P]$\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " b) `The Violation Time field is specified in a strange format. Find a way to make this a time attribute that you can use to divide into groups.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+----------------------+---------------------+\n",
      "|summary|Violation_Time_AM_PM|Violation_Time_Hour_12|Violation_Time_Minute|\n",
      "+-------+--------------------+----------------------+---------------------+\n",
      "|  count|             5431638|               5431638|              5431638|\n",
      "|   mean|                null|     6.843028751179663|   29.093529060662732|\n",
      "| stddev|                null|      3.73763347917092|    17.20503471486344|\n",
      "|    min|                   A|                     0|                    0|\n",
      "|    max|                   P|                    87|                   59|\n",
      "+-------+--------------------+----------------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import substring\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import udf\n",
    "nyc_df=nyc_df.withColumn('Violation_Time_AM_PM',substring(nyc_df.Violation_Time, 5, 1))\n",
    "nyc_df=nyc_df.withColumn('Violation_Time_Hour_12',substring(nyc_df.Violation_Time, 0, 2).cast(IntegerType()))\n",
    "nyc_df=nyc_df.withColumn('Violation_Time_Minute',substring(nyc_df.Violation_Time, 3, 2).cast(IntegerType()))\n",
    "nyc_df.describe(['Violation_Time_AM_PM','Violation_Time_Hour_12','Violation_Time_Minute']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyc_df.where(col(\"Violation_Time_AM_PM\").isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyc_df.where(col(\"Violation_Time_Hour_12\").isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyc_df.where(col(\"Violation_Time_Minute\").isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------------+---------------------+\n",
      "|Violation_Time|Violation_Time_Hour_24|Violation_Time_Minute|\n",
      "+--------------+----------------------+---------------------+\n",
      "|         1120A|                    11|                   20|\n",
      "|         0852P|                    20|                   52|\n",
      "|         0015A|                     0|                   15|\n",
      "|         0525A|                     5|                   25|\n",
      "|         0256P|                    14|                   56|\n",
      "|         1232A|                     0|                   32|\n",
      "|         1034A|                    10|                   34|\n",
      "|         1021A|                    10|                   21|\n",
      "|         0721A|                     7|                   21|\n",
      "|         0940A|                     9|                   40|\n",
      "|         1223P|                    12|                   23|\n",
      "|         1028A|                    10|                   28|\n",
      "|         0148A|                     1|                   48|\n",
      "|         1206P|                    12|                    6|\n",
      "|         0141P|                    13|                   41|\n",
      "|         0822A|                     8|                   22|\n",
      "|         0820A|                     8|                   20|\n",
      "|         1043A|                    10|                   43|\n",
      "|         0204P|                    14|                    4|\n",
      "|         0853A|                     8|                   53|\n",
      "+--------------+----------------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "h12_udf = udf(lambda h: h if h < 12 else 0, IntegerType())\n",
    "nyc_df = nyc_df.withColumn('Violation_Time_Hour_12',h12_udf('Violation_Time_Hour_12'))\n",
    "h24_udf = udf(lambda h, t: h+12 if t=='P' else h, IntegerType())\n",
    "nyc_df = nyc_df.withColumn('Violation_Time_Hour_24',h24_udf('Violation_Time_Hour_12','Violation_Time_AM_PM'))\n",
    "nyc_df.select('Violation_Time','Violation_Time_Hour_24','Violation_Time_Minute').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Summons_Number: long (nullable = true)\n",
      " |-- Plate_ID: string (nullable = true)\n",
      " |-- Registration_State: string (nullable = true)\n",
      " |-- Issue_Date: date (nullable = true)\n",
      " |-- Violation_Code: integer (nullable = true)\n",
      " |-- Vehicle_Body_Type: string (nullable = true)\n",
      " |-- Vehicle_Make: string (nullable = true)\n",
      " |-- Violation_Precinct: integer (nullable = true)\n",
      " |-- Issuer_Precinct: integer (nullable = true)\n",
      " |-- Violation_Time_Minute: integer (nullable = true)\n",
      " |-- Violation_Time_Hour_24: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nyc_df = nyc_df.drop('Violation_Time','Violation_Time_AM_PM','Violation_Time_Hour_12')\n",
    "nyc_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " c) `Divide 24 hours into six equal discrete bins of time. Choose the intervals as you see fit. For each of these groups, find the three most commonly occurring violations.`\n",
    "\n",
    "(Hint: Use the CASE-WHEN in SQL view to segregate into bins. To find the most commonly occurring violations, you can use an approach similar to the one mentioned in the hint for question 4.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  let's print out total number of entries per bin / bucketed values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+\n",
      "|count(1)|time_bin|\n",
      "+--------+--------+\n",
      "|  164531|       1|\n",
      "|  449861|       2|\n",
      "| 2163455|       3|\n",
      "| 1839925|       4|\n",
      "|  637513|       5|\n",
      "|  176353|       6|\n",
      "+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nyc_df.createOrReplaceTempView(\"nyc_dfTable\")\n",
    "time_nyc_df = spark.sql(\"\"\"\n",
    "                            SELECT Count(1),\n",
    "                                   time_bin\n",
    "                            FROM   (SELECT summons_number,\n",
    "                                           ( CASE\n",
    "                                               WHEN ( violation_time_hour_24 BETWEEN 0 AND 3 ) THEN 1\n",
    "                                               WHEN ( violation_time_hour_24 BETWEEN 4 AND 7 ) THEN 2\n",
    "                                               WHEN ( violation_time_hour_24 BETWEEN 8 AND 11 ) THEN 3\n",
    "                                               WHEN ( violation_time_hour_24 BETWEEN 12 AND 15 ) THEN 4\n",
    "                                               WHEN ( violation_time_hour_24 BETWEEN 16 AND 19 ) THEN 5\n",
    "                                               WHEN ( violation_time_hour_24 BETWEEN 20 AND 24 ) THEN 6\n",
    "                                               ELSE 7\n",
    "                                             -- Bin with invalid timeframe , let's check if we have some rows?\n",
    "                                             END ) AS Time_Bin\n",
    "                                    FROM   nyc_dftable)\n",
    "                            GROUP  BY 2\n",
    "                            ORDER  BY 2 ASC  \n",
    "                        \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_df.createOrReplaceTempView(\"nyc_dfTable\")\n",
    "time_nyc_df = spark.sql(\"\"\"\n",
    "                            SELECT summons_number,\n",
    "                                    Violation_Code ,\n",
    "                                   ( CASE\n",
    "                                       WHEN ( violation_time_hour_24 BETWEEN 0 AND 3 ) THEN 1\n",
    "                                       WHEN ( violation_time_hour_24 BETWEEN 4 AND 7 ) THEN 2\n",
    "                                       WHEN ( violation_time_hour_24 BETWEEN 8 AND 11 ) THEN 3\n",
    "                                       WHEN ( violation_time_hour_24 BETWEEN 12 AND 15 ) THEN 4\n",
    "                                       WHEN ( violation_time_hour_24 BETWEEN 16 AND 19 ) THEN 5\n",
    "                                       WHEN ( violation_time_hour_24 BETWEEN 20 AND 24 ) THEN 6\n",
    "                                       ELSE 7\n",
    "                                     END ) AS Time_Bin\n",
    "                            FROM   nyc_dftable    \n",
    "                        \"\"\")\n",
    "# time_nyc_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+--------+\n",
      "|summons_number|Violation_Code|Time_Bin|\n",
      "+--------------+--------------+--------+\n",
      "|    8478629828|            47|       3|\n",
      "|    5096917368|             7|       6|\n",
      "|    1407740258|            78|       1|\n",
      "|    1413656420|            40|       2|\n",
      "|    8480309064|            64|       4|\n",
      "+--------------+--------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_nyc_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+-------+----+\n",
      "|violation_code|time_bin|tickets|RANK|\n",
      "+--------------+--------+-------+----+\n",
      "|            21|       1|  36957|   1|\n",
      "|            40|       1|  25865|   2|\n",
      "|            78|       1|  15528|   3|\n",
      "|            14|       2|  74113|   1|\n",
      "|            40|       2|  60652|   2|\n",
      "|            21|       2|  57894|   3|\n",
      "|            21|       3| 598062|   1|\n",
      "|            36|       3| 348165|   2|\n",
      "|            38|       3| 176570|   3|\n",
      "|            36|       4| 286284|   1|\n",
      "|            38|       4| 240722|   2|\n",
      "|            37|       4| 167026|   3|\n",
      "|            38|       5| 102855|   1|\n",
      "|            14|       5|  75902|   2|\n",
      "|            37|       5|  70345|   3|\n",
      "|             7|       6|  26293|   1|\n",
      "|            40|       6|  22336|   2|\n",
      "|            14|       6|  21045|   3|\n",
      "+--------------+--------+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_nyc_df.cache()\n",
    "time_nyc_df.createOrReplaceTempView(\"time_nyc_dfTable\")\n",
    "spark.sql(\"\"\"\n",
    "\n",
    "              SELECT *\n",
    "                FROM   (SELECT violation_code,\n",
    "                               time_bin,\n",
    "                               tickets,\n",
    "                               Dense_rank()\n",
    "                                 OVER (\n",
    "                                   partition BY time_bin\n",
    "                                   ORDER BY tickets DESC) AS RANK\n",
    "                        FROM   (SELECT Count(summons_number) AS tickets,\n",
    "                                       violation_code,\n",
    "                                       time_bin\n",
    "                                FROM   time_nyc_dftable\n",
    "                                GROUP  BY violation_code,\n",
    "                                          time_bin) inner_q) outer_q\n",
    "                WHERE  rank <= 3\n",
    "                ORDER  BY time_bin ASC , RANK asc  \n",
    "\n",
    "            \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `Three most common occuring violations are listed for each of the time slot above ` <br>\n",
    "\n",
    "d) `Now, try another direction. For the three most commonly occurring violation codes, find the most common time of the day (in terms of the bins from the previous part).`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+-------+\n",
      "|time_bin|violation_code|tickets|\n",
      "+--------+--------------+-------+\n",
      "|       3|            21| 598062|\n",
      "|       3|            36| 348165|\n",
      "|       4|            36| 286284|\n",
      "|       4|            38| 240722|\n",
      "|       3|            38| 176570|\n",
      "|       5|            38| 102855|\n",
      "|       4|            21|  74718|\n",
      "|       2|            21|  57894|\n",
      "|       1|            21|  36957|\n",
      "|       6|            38|  20347|\n",
      "|       2|            36|  14782|\n",
      "|       5|            36|  13534|\n",
      "|       2|            38|   1273|\n",
      "|       1|            38|    312|\n",
      "|       5|            21|    259|\n",
      "|       6|            21|    184|\n",
      "+--------+--------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_nyc_df.cache()\n",
    "time_nyc_df.createOrReplaceTempView(\"time_nyc_dfTable\")\n",
    "spark.sql(\"\"\"\n",
    "                SELECT time_bin,\n",
    "                       violation_code,\n",
    "                       Count(summons_number) AS tickets\n",
    "                FROM   time_nyc_dftable\n",
    "                WHERE  violation_code IN (SELECT violation_code\n",
    "                                          FROM   (SELECT Count(summons_number) AS tickets,\n",
    "                                                         violation_code\n",
    "                                                  FROM   time_nyc_dftable\n",
    "                                                  GROUP  BY violation_code\n",
    "                                                  ORDER  BY tickets DESC\n",
    "                                                  LIMIT  3))\n",
    "                GROUP  BY time_bin,\n",
    "                          violation_code\n",
    "                ORDER  BY tickets DESC,\n",
    "                          time_bin ASC  \n",
    "\n",
    "            \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time bin `3` i.e. time between 8AM and 11AM are the time when there are most violations and violation codes 21, 36 and 38 are the most frequently occuring violations (Top 3)` <br>\n",
    "Code description is towards the end of the jupyter workbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6) Lets try and find some seasonality in this data:\n",
    "\n",
    " a) `First, divide the year into a certain number of seasons, and find the frequencies of tickets for each season.` (Hint: Use Issue Date to segregate into seasons.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- violation_code: integer (nullable = true)\n",
      " |-- summons_number: long (nullable = true)\n",
      " |-- Season: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nyc_df.createOrReplaceTempView(\"nyc_dfTable\")\n",
    "season_nyc_df = spark.sql(\"\"\"\n",
    "                                 SELECT violation_code,\n",
    "                                       summons_number,\n",
    "                                       CASE\n",
    "                                         WHEN ( Month(issue_date) IN ( 12, 1, 2 ) ) THEN \"winter\"\n",
    "                                         WHEN ( Month(issue_date) BETWEEN 3 AND 5 ) THEN \"spring\"\n",
    "                                         WHEN ( Month(issue_date) BETWEEN 6 AND 7 ) THEN \"summer\"\n",
    "                                         ELSE \"fall\"\n",
    "                                       END AS Season\n",
    "                                FROM   nyc_dftable  \n",
    "                            \"\"\")\n",
    "season_nyc_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b) `Then, find the three most common violations for each of these seasons.`\n",
    "\n",
    "(Hint: You can use an approach similar to the one mentioned in the hint for question 4.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+-------+----+\n",
      "|season|violation_code|tickets|RANK|\n",
      "+------+--------------+-------+----+\n",
      "|winter|            21| 238182|   1|\n",
      "|winter|            36| 221268|   2|\n",
      "|winter|            38| 187386|   3|\n",
      "|summer|            21| 127265|   1|\n",
      "|summer|            36|  96663|   2|\n",
      "|summer|            38|  83517|   3|\n",
      "|spring|            21| 402415|   1|\n",
      "|spring|            36| 344834|   2|\n",
      "|spring|            38| 271167|   3|\n",
      "|  fall|            46|    288|   1|\n",
      "|  fall|            21|    212|   2|\n",
      "|  fall|            40|    149|   3|\n",
      "+------+--------------+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "season_nyc_df.createOrReplaceTempView(\"season_nyc_dfTable\")\n",
    "spark.sql(\"\"\"\n",
    "                SELECT *\n",
    "                FROM   (SELECT season,\n",
    "                               violation_code,\n",
    "                               tickets,\n",
    "                               DENSE_RANK() OVER ( PARTITION BY season ORDER BY tickets desc) AS RANK \n",
    "                        FROM   (SELECT season,\n",
    "                                       violation_code,\n",
    "                                       COUNT(DISTINCT summons_number) AS Tickets \n",
    "                                FROM   season_nyc_dftable \n",
    "                                GROUP  BY season,\n",
    "                                          violation_code) inner_q  ) outer_q\n",
    "                WHERE  RANK <= 3  \n",
    "\n",
    "\n",
    "\n",
    "            \"\"\").show()            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) `Winter, Summer and Spring` have violation codes `21, 36 and 38` that tops the list <br>\n",
    "2) During `Fall` we have violation codes `46,  21 and 40` that tops the list \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7)  The fines collected from all the instances of parking violation constitute a source of revenue for the NYC Police Department. Lets take an example of estimating this for the three most commonly occurring codes:\n",
    "\n",
    "a) `Find the total occurrences of the three most common violation code`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_df.createOrReplaceTempView(\"nyc_dfTable\")\n",
    "violation_pdf = spark.sql(\"\"\"\n",
    "                                SELECT violation_code,\n",
    "                                       COUNT(DISTINCT summons_number) AS Tickets \n",
    "                                FROM   season_nyc_dftable \n",
    "                                GROUP  BY violation_code \n",
    "                                ORDER  BY tickets desc  \n",
    "                            \"\"\").limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tickets</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>violation_code</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>768074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>662765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>542079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Tickets\n",
       "violation_code         \n",
       "21               768074\n",
       "36               662765\n",
       "38               542079"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "violation_pdf = violation_pdf.set_index('violation_code')\n",
    "violation_pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`b) Then, visit the website:  http://www1.nyc.gov/site/finance/vehicles/services-violation-codes.page . It lists the fines associated with different violation codes. Theyre divided into two categories: one for the highest-density locations in the city and the other for the rest of the city. For the sake of simplicity, take the average of the two.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|CODE|DEFINITION|Manhattan 96th St. & below|All Other Areas|Average|\n",
    "|------|------|------|------|------|\n",
    "|21|Street Cleaning: No parking where parking is not allowed by sign, street marking or traffic control device.|\\$65|\\$45|\\$55|\n",
    "|36|Exceeding the posted speed limit in or near a designated school zone.|\\$50|\\$50|\\$50|\n",
    "|38|Failing to show a receipt or tag in the windshield.Drivers get a 5-minute grace period past the expired time on parking meter receipts.|\\$65|\\$35|\\$50|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`c) Using this information, find the total amount collected for the three violation codes with the maximum tickets. State the code that has the highest total collection`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tickets</th>\n",
       "      <th>Fine</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>violation_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>768074</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>662765</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>542079</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Tickets  Fine\n",
       "violation_code               \n",
       "21               768074    55\n",
       "36               662765    50\n",
       "38               542079    50"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fines = {'violation_Code': [21,36,38], \\\n",
    "        'Fine': [55,50,50]}\n",
    "fines_pdf = pd.DataFrame(fines)\n",
    "fines_pdf = fines_pdf.set_index('violation_Code')\n",
    "violation_pdf=violation_pdf.merge(fines_pdf,left_index=True,right_index=True)\n",
    "violation_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tickets</th>\n",
       "      <th>Fine</th>\n",
       "      <th>Collected_Amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>violation_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>768074</td>\n",
       "      <td>55</td>\n",
       "      <td>42244070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>662765</td>\n",
       "      <td>50</td>\n",
       "      <td>33138250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>542079</td>\n",
       "      <td>50</td>\n",
       "      <td>27103950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Tickets  Fine  Collected_Amount\n",
       "violation_code                                 \n",
       "21               768074    55          42244070\n",
       "36               662765    50          33138250\n",
       "38               542079    50          27103950"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "violation_pdf['Collected_Amount'] = violation_pdf['Tickets'] * violation_pdf['Fine']\n",
    "violation_pdf.sort_values(by='Collected_Amount',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`d)What can you intuitively infer from these findings?` <br>\n",
    "\n",
    "1) Code 21 tops the list : `Street Cleaning: No parking where parking is not allowed by sign, street marking or traffic control device.`Increasing the fines increase the revenue here, this can be used by department for civic amenity spending. Increasing the fine would also prevent irregular parking. <br>\n",
    "2) Code 36 is second in the list: `Exceeding the posted speed limit in or near a designated school zone.`. Increased tickets for this code indicates an issue and a hazard for school kids. More analyis can be made why there is exceeded speed and more speed breakers should be introduced in the school zone <br>\n",
    "3) Code 38 is third on the list : `Failing to show a receipt or tag in the windshield.Drivers get a 5-minute grace period past the expired time on parking meter receipts.`. Revenue from the NYPD needs to be spent on citizen education drive to prevent this violation \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary and conclusion / Inferences derived from the case study\n",
    "\n",
    "\n",
    "1) `FORD`, `TOYOTA`, `HONDA`, `NISSAN` and `CHEVROLET` are the top 5 body types in records. This indicates violation has been recorded for a commoner and not any special kind of vehicles  <br>\n",
    "2) The highest violation frequency is of `almost 1.9 million times` in a year <br>\n",
    "3) Most of these vehicles are used for `transport and delivery`. This indicates that drivers are driven by required `delivery/arrival time` to `violate regulations`. Evenly distributed `special parking zones` for such vehicles can ease traffic challenges <br>\n",
    "4) Violation codes `21, 36 and 38` tops the list and description is provided above <br>\n",
    "5) Observation `Excluding incorrectly tagged 0 ` shows that Number of tickets issued by `Violation Precinct` is less than the number of tickets `Issuer precinct `. This indicates that there is a probability of shortage of manpower in `Issuer precinct `  <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
